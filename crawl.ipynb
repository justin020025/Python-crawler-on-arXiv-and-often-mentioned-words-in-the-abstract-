{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "page 1-50\n",
    "https://arxiv.org/search/?query=cache&searchtype=all&abstracts=show&order=-announced_date_first&size=50<br>\n",
    "51-100\n",
    "https://arxiv.org/search/?query=cache&searchtype=all&source=header&order=-announced_date_first&size=50&abstracts=show&start=50<br>\n",
    "101-150\n",
    "https://arxiv.org/search/?query=cache&searchtype=all&source=header&order=-announced_date_first&size=50&abstracts=show&start=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on the observation above\n",
    "def url_generator(search, page):\n",
    "    if page==1:\n",
    "        return \"https://arxiv.org/search/?query=\"+search+\"&searchtype=all&abstracts=show&order=-announced_date_first&size=50\"\n",
    "    else:\n",
    "        return \"https://arxiv.org/search/?query=\"+search+\"&searchtype=all&source=header&order=-announced_date_first&size=50&abstracts=show&start=\"+str((page-1)*50)\n",
    "\n",
    "#url of the serch for photon looks like\n",
    "#https://arxiv.org/search/?query=photon&searchtype=all&abstracts=show&order=-announced_date_first&size=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url2soup(url):\n",
    "    html = urlopen(url).read()\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_link(paper_soup):\n",
    "    manylink = paper_soup.find('ol')('p','list-title')\n",
    "    link = [L.a['href'] for L in manylink]\n",
    "    return link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find title\n",
    "```python\n",
    "\n",
    "asoup = url2soup('https://arxiv.org/abs/1902.00135')\n",
    "c = asoup.find('h1',\"title mathjax\")\n",
    "c\n",
    "```\n",
    "\n",
    "```\n",
    "<h1 class=\"title mathjax\"><span class=\"descriptor\">Title:</span>Cache-aided Interference Management Using Hypercube Combinatorial Cache Designs</h1>\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "\n",
    "c.text\n",
    "```\n",
    "\n",
    "```\n",
    "'Title:Cache-aided Interference Management Using Hypercube Combinatorial Cache Designs'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find authors\n",
    "```python\n",
    "au = url2soup('https://arxiv.org/abs/1812.05955')\n",
    "a = au.find('div', 'authors')\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "<div class=\"authors\"><span class=\"descriptor\">Authors:</span><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Rolinger%2C+T+B\">Thomas B. Rolinger</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Krieger%2C+C+D\">Christopher D. Krieger</a>\n",
    "</div>\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "a.text\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "'Authors:Thomas B. Rolinger, Christopher D. Krieger\\n'\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find abstract\n",
    "```python\n",
    "k = url2soup('https://arxiv.org/abs/1812.06410')\n",
    "abs = k.find('blockquote')\n",
    "abs\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  Knowledge Graph (KG) embedding is a fundamental problem in data mining\n",
    "research with many real-world applications. It aims to encode the entities and\n",
    "relations in the graph into low dimensional vector space, which can be used for\n",
    "subsequent algorithms. Negative sampling, which samples negative triplets from\n",
    "non-observed ones in the training data, is an important step in KG embedding.\n",
    "Recently, generative adversarial network (GAN), has been introduced in negative\n",
    "sampling. By sampling negative triplets with large scores, these methods avoid\n",
    "the problem of vanishing gradient and thus obtain better performance. However,\n",
    "using GAN makes the original model more complex and hard to train, where\n",
    "reinforcement learning must be used. In this paper, motivated by the\n",
    "observation that negative triplets with large scores are important but rare, we\n",
    "propose to directly keep track of them with the cache. However, how to sample\n",
    "from and update the cache are two important questions. We carefully design the\n",
    "solutions, which are not only efficient but also achieve a good balance between\n",
    "exploration and exploitation. In this way, our method acts as a \"distilled\"\n",
    "version of previous GA-based methods, which does not waste training time on\n",
    "additional parameters to fit the full distribution of negative triplets. The\n",
    "extensive experiments show that our method can gain significant improvement in\n",
    "various KG embedding models, and outperform the state-of-the-art negative\n",
    "sampling methods based on GAN.\n",
    "</blockquote>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_author_abs(link):\n",
    "    soup = url2soup(link)\n",
    "    title = soup.find('h1',\"title mathjax\").text[6:]\n",
    "    \n",
    "    author = soup.find('div', 'authors').text\n",
    "    author = author[8:]               #change format\n",
    "    author = author.split(',')\n",
    "    author[-1] = re.sub('[\\n\\t]','',author[-1])\n",
    "    \n",
    "    abst = soup.find('blockquote').text[11:]\n",
    "    \n",
    "    return title, author, abst\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#arg = sys.argv\n",
    "#keyword = arg[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,3):\n",
    "    link.extend(paper_link(url2soup(url_generator(\"data\",i))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "title, author, abst = [], [], []\n",
    "for L in link:\n",
    "    A, B, C = title_author_abs(L)\n",
    "    title.append(A)\n",
    "    author.append(B)\n",
    "    abst.append(C)\n",
    "    time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('paper_info.txt','w',encoding = 'utf8') as f:\n",
    "    for i in range(100):\n",
    "\n",
    "        f.write(link[i]+'\\n')\n",
    "\n",
    "        f.write(title[i]+'\\n')\n",
    "\n",
    "        for name in author[i]:\n",
    "            f.write(name+';')\n",
    "        f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Amedeo Sapio',\n",
       "  ' Marco Canini',\n",
       "  ' Chen-Yu Ho',\n",
       "  ' Jacob Nelson',\n",
       "  ' Panos Kalnis',\n",
       "  ' Changhoon Kim',\n",
       "  ' Arvind Krishnamurthy',\n",
       "  ' Masoud Moshref',\n",
       "  ' Dan R. K. Ports',\n",
       "  ' Peter Richtárik'],\n",
       " ['Sanjeev Raja', ' Ernest Fokoué'],\n",
       " ['D. Cazau (for the OSmOSE team)    '],\n",
       " ['Will Handley', ' Pablo Lemos'],\n",
       " ['Nikoli Dryden',\n",
       "  ' Naoya Maruyama',\n",
       "  ' Tom Benson',\n",
       "  ' Tim Moon',\n",
       "  ' Marc Snir',\n",
       "  ' Brian Van Essen'],\n",
       " ['Sébastien Lemaire',\n",
       "  ' Yu Cao',\n",
       "  ' Thomas Kluyver',\n",
       "  ' Daniel Hausner',\n",
       "  ' Camil Vasilovici',\n",
       "  ' Zhong-yuen Lee',\n",
       "  ' Umberto José Varbaro',\n",
       "  ' Sophia M. Schillai'],\n",
       " ['James E. Barrett',\n",
       "  ' Aylin Cakiroglu',\n",
       "  ' Catey Bunce',\n",
       "  ' Anoop Shah',\n",
       "  ' Spiros Denaxas'],\n",
       " ['Balázs Dobi', ' András Zempléni'],\n",
       " ['Vittoria Sposini', ' Ralf Metzler', ' Gleb Oshanin'],\n",
       " ['Benyamin Ghojogh', ' Mark Crowley', ' Fakhri Karray'],\n",
       " ['V. Bondarenko (LS2N',\n",
       "  ' ECN)',\n",
       "  ' Simona Petrakieva',\n",
       "  ' Ina Taralova (LS2N',\n",
       "  ' ECN)',\n",
       "  ' Desislav Andreev'],\n",
       " ['Shahrzad Gholami',\n",
       "  ' Lily Xu',\n",
       "  ' Sara Mc Carthy',\n",
       "  ' Bistra Dilkina',\n",
       "  ' Andrew Plumptre',\n",
       "  ' Milind Tambe',\n",
       "  ' Rohit Singh',\n",
       "  ' Mustapha Nsubuga',\n",
       "  ' Joshua Mabonga',\n",
       "  ' Margaret Driciru',\n",
       "  ' Fred Wanyama',\n",
       "  ' Aggrey Rwetsiba',\n",
       "  ' Tom Okello',\n",
       "  ' Eric Enyel'],\n",
       " ['Leonardo N. Ferreira',\n",
       "  ' Didier A. Vega-Oliveros',\n",
       "  ' Liang Zhao',\n",
       "  ' Manoel F. Cardoso',\n",
       "  ' Elbert E. N. Macau'],\n",
       " ['Sumanta Kumar Das'],\n",
       " ['Csaba Vincze'],\n",
       " ['Quoc Phong Nguyen',\n",
       "  ' Kar Wai Lim',\n",
       "  ' Dinil Mon Divakaran',\n",
       "  ' Kian Hsiang Low',\n",
       "  ' Mun Choon Chan'],\n",
       " ['Hideki Tanimura',\n",
       "  ' Gary Hinshaw',\n",
       "  ' Ian G. McCarthy',\n",
       "  ' Ludovic Van Waerbeke',\n",
       "  ' Nabila Aghanim',\n",
       "  ' Yin-Zhe Ma',\n",
       "  ' Alexander Mead',\n",
       "  ' Tilman Tröster',\n",
       "  ' Alireza Hojjati',\n",
       "  ' Bruno Moraes'],\n",
       " ['Peter Kroll', ' Kornelija Passek-Kumerički'],\n",
       " ['Qiuwen Lou',\n",
       "  ' Indranil Palit',\n",
       "  ' Tang Li',\n",
       "  ' Andras Horvath',\n",
       "  ' Michael Niemier',\n",
       "  ' X. Sharon Hu'],\n",
       " ['Basit Qureshi', ' Anis Koubaa'],\n",
       " ['Vasileios Sideridis',\n",
       "  ' Andrew Zacharakis',\n",
       "  ' George Tzagkarakis',\n",
       "  ' Maria Papadopouli'],\n",
       " ['Géraldine Castel (ILCEA4)',\n",
       "  ' Genoveva Vargas-Solar (ILCEA4)',\n",
       "  ' Javier Espinosa-Oviedo (TU Delft)    '],\n",
       " ['Panagiota Kiourti', ' Kacper Wardega', ' Susmit Jha', ' Wenchao Li'],\n",
       " ['Mark G. Allen',\n",
       "  ' Patrick Dowler',\n",
       "  ' Janet D. Evans',\n",
       "  ' Chenzhou Cui',\n",
       "  ' Tim Jenness'],\n",
       " ['G. Fabbiano',\n",
       "  ' M. Elvis',\n",
       "  ' A. Accomazzi',\n",
       "  ' G. B. Berriman',\n",
       "  ' N. Brickhouse',\n",
       "  ' S. Bose',\n",
       "  ' D. Carrera',\n",
       "  ' I. Chilingarian',\n",
       "  ' F. Civano',\n",
       "  ' B. Czerny',\n",
       "  \" R. D'Abrusco\",\n",
       "  ' B. Diemer',\n",
       "  ' J. Drake',\n",
       "  ' R. Emami Meibody. J. R. Farah',\n",
       "  ' G. G. Fazio',\n",
       "  ' E. Feigelson',\n",
       "  ' F. Fornasini',\n",
       "  ' Jay Gallagher',\n",
       "  ' J. Grindlay',\n",
       "  ' L. Hernquist',\n",
       "  ' D. J. James',\n",
       "  ' M. Karovska',\n",
       "  ' V. Kashyap',\n",
       "  ' D.-W. Kim',\n",
       "  ' G. M. Lacy',\n",
       "  ' J. Lazio',\n",
       "  ' E. Lusso',\n",
       "  ' W. P. Maksym',\n",
       "  ' R. Martinez Galarza',\n",
       "  ' J. Mazzarella',\n",
       "  ' M. Ntampaka',\n",
       "  ' G. Risaliti',\n",
       "  ' D. Sanders',\n",
       "  ' N. Scoville',\n",
       "  ' I. Shapiro',\n",
       "  ' A. Siemiginowska',\n",
       "  ' A. Smth',\n",
       "  ' S. Smith',\n",
       "  ' A. Szentgyorgyi',\n",
       "  ' S. Tacchella',\n",
       "  ' A. Thakar',\n",
       "  ' V. Tolls',\n",
       "  ' S. Vrtilek',\n",
       "  ' B. Wilkes',\n",
       "  ' D. Wilner',\n",
       "  ' S. P. Willner',\n",
       "  ' S. J. Wolk',\n",
       "  ' J.-H. Zhao'],\n",
       " ['Masoud Fekri', ' Babak Barazandeh'],\n",
       " ['Junzhe Zhang', ' Sai Ho Yeung', ' Yao Shu', ' Bingsheng He', ' Wei Wang'],\n",
       " ['Pedro T. P. Lopes', ' Nikolaos Roidos'],\n",
       " ['Thomas Schnake', ' David Bauer'],\n",
       " ['Rafael Orellana',\n",
       "  ' Pedro Escarate',\n",
       "  ' Michel Cure',\n",
       "  ' Alejandra Christen',\n",
       "  ' Rodrigo Carvajal',\n",
       "  ' Juan Carlos Agüero'],\n",
       " ['C. Nigro',\n",
       "  ' C. Deil',\n",
       "  ' R. Zanin',\n",
       "  ' T. Hassan',\n",
       "  ' J. King',\n",
       "  ' J.E. Ruiz',\n",
       "  ' L. Saha',\n",
       "  ' R. Terrier',\n",
       "  ' K. Brügge',\n",
       "  ' M. Nöthe',\n",
       "  ' R. Bird',\n",
       "  ' T. T. Y. Lin',\n",
       "  ' J. Aleksić',\n",
       "  ' C. Boisson',\n",
       "  ' J.L. Contreras',\n",
       "  ' A. Donath',\n",
       "  ' L. Jouvin',\n",
       "  ' N. Kelley-Hoskins',\n",
       "  ' B. Khelifi',\n",
       "  ' K. Kosack',\n",
       "  ' J. Rico',\n",
       "  ' A. Sinha'],\n",
       " ['Seyyed Yousef Oleyaei-Motlagh', ' Adan Ernesto Vela'],\n",
       " ['Juan J. Clariá',\n",
       "  ' M. Celeste Parisi',\n",
       "  ' Tali Palma',\n",
       "  ' Andrea V. Ahumada',\n",
       "  ' Carla G. Oviedo'],\n",
       " ['Loizos Koutsantonis',\n",
       "  ' Aristotelis-Nikolaos Rapsomanikis',\n",
       "  ' Efstathios Stiliaris',\n",
       "  ' Costas N. Papanicolas'],\n",
       " ['Michael Azmy', ' Peng Shi', ' Jimmy Lin', ' Ihab F. Ilyas'],\n",
       " ['J. M. TenBarge',\n",
       "  ' J. Ng',\n",
       "  ' J. Juno',\n",
       "  ' L. Wang',\n",
       "  ' A. H. Hakim',\n",
       "  ' A. Bhattacharjee'],\n",
       " ['Chen Liu', ' Ryota Tomioka', ' Volkan Cevher'],\n",
       " ['J. Ian Munro', ' Yakov Nekrich'],\n",
       " ['Clarissa Braccia',\n",
       "  ' Meritxell Pons Espinal',\n",
       "  ' Mattia Pini',\n",
       "  ' Davide De Pietri Tonelli',\n",
       "  ' Andrea Armirotti'],\n",
       " ['Samuel C. Gutekunst', ' Karola Mészáros', ' T. Kyle Petersen'],\n",
       " ['Katerina Papagiannouli'],\n",
       " ['Colin Lonsdale',\n",
       "  ' Elena Orlando',\n",
       "  ' Gregg Hallinan',\n",
       "  ' Greg Taylor',\n",
       "  ' Clive Dickinson'],\n",
       " ['Rogelio A Mancisidor',\n",
       "  ' Michael Kampffmeyer',\n",
       "  ' Kjersti Aas',\n",
       "  ' Robert Jenssen'],\n",
       " ['Janka Chlebíková',\n",
       "  ' Cristina Bazgan',\n",
       "  ' Clément Dallard',\n",
       "  ' Thomas Pontoizeau'],\n",
       " ['Donghoon Lee', ' Tomas Pfister', ' Ming-Hsuan Yang'],\n",
       " ['Ripon Patgiri', ' Sabuzima Nayak', ' Samir Kumar Borgohain'],\n",
       " ['Lukas Koch'],\n",
       " ['Ripon Patgiri', ' Sabuzima Nayak', ' Samir Kumar Borgohain'],\n",
       " ['Claudio Attaccalite',\n",
       "  ' Maurizia Palummo',\n",
       "  ' Elena Cannuccia',\n",
       "  ' Myrta Grüning'],\n",
       " ['Constantin Enea', ' Suha Orhun Mutluergil', ' Gustavo Petri', ' Chao Wang'],\n",
       " ['L. Perivolaropoulos', ' F. Skara'],\n",
       " ['Philip Sellars', ' Angelica Aviles-Rivero', ' Carola-Bibiane Schönlieb'],\n",
       " ['Floyd W. Stecker', ' Chris R. Shrader', ' Matthew. A. Malkan'],\n",
       " ['Maaike van Kooten', ' Niek Doelman', ' Matthew Kenworthy'],\n",
       " ['Atte Aalto', ' Jorge Goncalves'],\n",
       " ['Kenichi Kumatani',\n",
       "  ' Wu Minhua',\n",
       "  ' Shiva Sundaram',\n",
       "  ' Nikko Strom',\n",
       "  ' Bjorn Hoffmeister'],\n",
       " ['Liyuan Pan',\n",
       "  ' Richard Hartley',\n",
       "  ' Cedric Scheerlinck',\n",
       "  ' Miaomiao Liu',\n",
       "  ' Xin Yu',\n",
       "  ' Yuchao Dai'],\n",
       " ['Nicolas Girard (UCA',\n",
       "  ' TITANE)',\n",
       "  ' Guillaume Charpiat (TAU)',\n",
       "  ' Yuliya Tarabalka (UCA',\n",
       "  ' TITANE)    '],\n",
       " ['C. Neiner', ' J. Morin', ' J.-C. Bouret', ' L. Fossati'],\n",
       " ['Shilpa Manandhar', ' Soumyabrata Dev', ' Yee Hui Lee', ' Stefan Winkler'],\n",
       " ['Vyacheslav N. Shalyapin', ' Luis J. Goicoechea'],\n",
       " ['S. Ait Elkorchi', ' M. Chabab', ' A. El Batoul', ' A. Lahbas', ' M. Oulne'],\n",
       " ['Achim Zeileis',\n",
       "  ' Jason C. Fisher',\n",
       "  ' Kurt Hornik',\n",
       "  ' Ross Ihaka',\n",
       "  ' Claire D. McWhite',\n",
       "  ' Paul Murrell',\n",
       "  ' Reto Stauffer',\n",
       "  ' Claus O. Wilke'],\n",
       " ['Ellen C Caniglia', ' Eleanor J Murray', ' Miguel A Hernan', ' Zach Shahn'],\n",
       " ['Christos Kotsalos', ' Jonas Latt', ' Bastien Chopard'],\n",
       " ['Martin Hansen', ' Alessandro Lupo', ' Nazario Tantalo'],\n",
       " ['Ioannis Agtzidis', ' Mikhail Startsev', ' Michael Dorr'],\n",
       " ['Zerong Zheng', ' Tao Yu', ' Yixuan Wei', ' Qionghai Dai', ' Yebin Liu'],\n",
       " ['Dima Kagan', ' Thomas Chesney', ' Michael Fire'],\n",
       " ['Chanwoo Jeong',\n",
       "  ' Sion Jang',\n",
       "  ' Hyuna Shin',\n",
       "  ' Eunjeong Park',\n",
       "  ' Sungchul Choi'],\n",
       " ['Guenter Hesse',\n",
       "  ' Christoph Matthies',\n",
       "  ' Werner Sinzig',\n",
       "  ' Matthias Uflacker'],\n",
       " ['Rinaldo Colombo', ' Vincent Perrollaz (IDP)    '],\n",
       " ['Desmond C. Ong', ' Harold Soh', ' Jamil Zaki', ' Noah D. Goodman'],\n",
       " ['Shiwen He',\n",
       "  ' Ju Ren',\n",
       "  ' Jiaheng Wang',\n",
       "  ' Yongming Huang',\n",
       "  ' Yaoxue Zhang',\n",
       "  ' Weihua Zhuang',\n",
       "  ' Sherman (Xuemin)Shen'],\n",
       " ['Antti J. Mäkinen', ' Koos C. J. Zevenhoven', ' Risto J. Ilmoniemi'],\n",
       " ['E.Churazov',\n",
       "  ' I.Khabibullin',\n",
       "  ' R.Sunyaev',\n",
       "  ' A.Vikhlinin',\n",
       "  ' G.Ponti',\n",
       "  ' C.Federrath',\n",
       "  ' S.Walch'],\n",
       " ['Mahdieh Ahmadi', ' James Roberts', ' Emilio Leonardi', ' Ali Movaghar'],\n",
       " ['Belle Collaboration: K. Chilikin',\n",
       "  ' I. Adachi',\n",
       "  ' D. M. Asner',\n",
       "  ' V. Aulchenko',\n",
       "  ' T. Aushev',\n",
       "  ' R. Ayad',\n",
       "  ' V. Babu',\n",
       "  ' I. Badhrees',\n",
       "  ' V. Bansal',\n",
       "  ' P. Behera',\n",
       "  ' C. Beleño',\n",
       "  ' M. Berger',\n",
       "  ' V. Bhardwaj',\n",
       "  ' T. Bilka',\n",
       "  ' J. Biswal',\n",
       "  ' A. Bobrov',\n",
       "  ' A. Bondar',\n",
       "  ' A. Bozek',\n",
       "  ' M. Bračko',\n",
       "  ' T. E. Browder',\n",
       "  ' M. Campajola',\n",
       "  ' L. Cao',\n",
       "  ' D. Červenkov',\n",
       "  ' V. Chekelian',\n",
       "  ' A. Chen',\n",
       "  ' B. G. Cheon',\n",
       "  ' K. Cho',\n",
       "  ' S.-K. Choi',\n",
       "  ' Y. Choi',\n",
       "  ' D. Cinabro',\n",
       "  ' S. Cunliffe',\n",
       "  ' S. Di Carlo',\n",
       "  ' Z. Doležal',\n",
       "  ' T. V. Dong',\n",
       "  ' S. Eidelman',\n",
       "  ' D. Epifanov',\n",
       "  ' J. E. Fast',\n",
       "  ' T. Ferber',\n",
       "  ' B. G. Fulsom',\n",
       "  ' R. Garg',\n",
       "  ' V. Gaur',\n",
       "  ' N. Gabyshev',\n",
       "  ' A. Garmash',\n",
       "  ' M. Gelb',\n",
       "  ' A. Giri',\n",
       "  ' P. Goldenzweig',\n",
       "  ' O. Grzymkowska',\n",
       "  ' J. Haba',\n",
       "  ' T. Hara',\n",
       "  ' K. Hayasaka',\n",
       "  ' H. Hayashii',\n",
       "  ' W.-S. Hou',\n",
       "  ' C.-L. Hsu',\n",
       "  ' K. Inami',\n",
       "  ' A. Ishikawa',\n",
       "  ' R. Itoh',\n",
       "  ' M. Iwasaki',\n",
       "  ' Y. Iwasaki',\n",
       "  ' W. W. Jacobs',\n",
       "  ' S. Jia',\n",
       "  ' Y. Jin',\n",
       "  ' D. Joffe',\n",
       "  ' K. K. Joo',\n",
       "  ' T. Julius',\n",
       "  ' A. B. Kaliyar',\n",
       "  ' G. Karyan',\n",
       "  ' Y. Kato',\n",
       "  ' C. Kiesling',\n",
       "  ' C. H. Kim',\n",
       "  ' D. Y. Kim',\n",
       "  ' S. H. Kim',\n",
       "  ' K. Kinoshita',\n",
       "  ' P. Kodyš',\n",
       "  ' S. Korpar',\n",
       "  ' D. Kotchetkov',\n",
       "  ' R. Kroeger',\n",
       "  ' P. Krokovny',\n",
       "  ' R. Kulasiri',\n",
       "  ' R. Kumar',\n",
       "  ' Y.-J. Kwon',\n",
       "  ' K. Lalwani',\n",
       "  ' J. S. Lange',\n",
       "  ' J. K. Lee',\n",
       "  ' J. Y. Lee',\n",
       "  ' S. C. Lee',\n",
       "  ' L. K. Li',\n",
       "  ' Y. B. Li',\n",
       "  ' L. Li Gioi',\n",
       "  ' J. Libby',\n",
       "  ' D. Liventsev',\n",
       "  ' P.-C. Lu',\n",
       "  ' T. Luo',\n",
       "  ' J. MacNaughton',\n",
       "  ' C. MacQueen',\n",
       "  ' M. Masuda',\n",
       "  ' T. Matsuda',\n",
       "  ' D. Matvienko',\n",
       "  ' M. Merola',\n",
       "  ' K. Miyabayashi',\n",
       "  ' R. Mizuk\\n\\n<!--\\nfunction toggleAuthorList(whichLayer',\n",
       "  'toggleThis)\\n{\\n  var elem',\n",
       "  ' vis',\n",
       "  ' tempToggle;\\n  tempToggle=toggleThis;\\n  if( document.getElementById ) // standard\\n      elem = document.getElementById( whichLayer );\\n  else if( document.all ) // old msie versions\\n      elem = document.all[whichLayer];\\n  else if( document.layers ) // nn4\\n      elem = document.layers[whichLayer];\\n  vis = elem.style;\\n  // if the style.display value is blank we try to figure it out here\\n  if(vis.display==\\'\\'&&elem.offsetWidth!=undefined&&elem.offsetHeight!=undefined)\\n    vis.display = (elem.offsetWidth!=0&&elem.offsetHeight!=0)?\\'inline\\':\\'none\\';\\n  vis.display = (vis.display==\\'\\'||vis.display==\\'inline\\')?\\'none\\':\\'inline\\';\\n\\n  // toggle link inner text\\n  status = vis.display;\\n  if(status==\\'none\\'){\\n      document.getElementById(\\'toggle\\').innerHTML = tempToggle ;\\n      document.getElementById(\\'toggle\\').title = \"Show Entire Author List\";\\n  }\\n  else if(status==\\'inline\\'){\\n      document.getElementById(\\'toggle\\').innerHTML = \"(collapse list)\";\\n      document.getElementById(\\'toggle\\').title = \"Collapse Author List\";\\n  }\\n}\\n//-->\\n\\n\\n        ',\n",
       "  ' G. B. Mohanty',\n",
       "  ' T. Mori',\n",
       "  ' M. Nakao',\n",
       "  ' K. J. Nath',\n",
       "  ' M. Nayak',\n",
       "  ' M. Niiyama',\n",
       "  ' N. K. Nisar',\n",
       "  ' S. Nishida',\n",
       "  ' K. Nishimura',\n",
       "  ' H. Ono',\n",
       "  ' Y. Onuki',\n",
       "  ' P. Pakhlov',\n",
       "  ' G. Pakhlova',\n",
       "  ' B. Pal',\n",
       "  ' S. Pardi',\n",
       "  ' H. Park',\n",
       "  ' S. Patra',\n",
       "  ' S. Paul',\n",
       "  ' T. K. Pedlar',\n",
       "  ' R. Pestotnik',\n",
       "  ' L. E. Piilonen',\n",
       "  ' V. Popov',\n",
       "  ' M. Ritter',\n",
       "  ' A. Rostomyan',\n",
       "  ' G. Russo',\n",
       "  ' Y. Sakai',\n",
       "  ' M. Salehi',\n",
       "  ' S. Sandilya',\n",
       "  ' T. Sanuki',\n",
       "  ' V. Savinov',\n",
       "  ' O. Schneider',\n",
       "  ' G. Schnell',\n",
       "  ' C. Schwanda',\n",
       "  ' Y. Seino',\n",
       "  ' K. Senyo',\n",
       "  ' M. E. Sevior',\n",
       "  ' C. P. Shen',\n",
       "  ' J.-G. Shiu',\n",
       "  ' B. Shwartz',\n",
       "  ' F. Simon',\n",
       "  ' A. Sokolov',\n",
       "  ' E. Solovieva',\n",
       "  ' M. Starič',\n",
       "  ' Z. S. Stottler',\n",
       "  ' J. F. Strube',\n",
       "  ' T. Sumiyoshi',\n",
       "  ' W. Sutcliffe',\n",
       "  ' M. Takizawa',\n",
       "  ' U. Tamponi',\n",
       "  ' K. Tanida',\n",
       "  ' F. Tenchini',\n",
       "  ' K. Trabelsi',\n",
       "  ' M. Uchida',\n",
       "  ' S. Uno',\n",
       "  ' P. Urquijo',\n",
       "  ' Y. Usov',\n",
       "  ' R. Van Tonder',\n",
       "  ' G. Varner',\n",
       "  ' A. Vinokurova',\n",
       "  ' B. Wang',\n",
       "  ' C. H. Wang',\n",
       "  ' M.-Z. Wang',\n",
       "  ' P. Wang',\n",
       "  ' M. Watanabe',\n",
       "  ' S. Watanuki',\n",
       "  ' E. Won',\n",
       "  ' S. B. Yang',\n",
       "  ' H. Ye',\n",
       "  ' J. Yelton',\n",
       "  ' J. H. Yin',\n",
       "  ' C. Z. Yuan',\n",
       "  ' J. Zhang',\n",
       "  ' Z. P. Zhang',\n",
       "  ' V. Zhilich',\n",
       "  ' V. Zhukova    et al. (75 additional authors not shown)\\xa0You must enable JavaScript to view entire author list.'],\n",
       " ['Mikito Nanashima'],\n",
       " ['Yukie Sano', ' Hideki Takayasu', ' Shlomo Havlin', ' Misako Takayasu'],\n",
       " ['Yuan Cao', ' Lijuan Han', ' Xiaojin Zhao', ' Xiaofang Pan'],\n",
       " ['Hongfeng Wang',\n",
       "  ' Weiwei Zhu',\n",
       "  ' Ping Guo',\n",
       "  ' Di Li',\n",
       "  ' Sibo Feng',\n",
       "  ' Qian Yin',\n",
       "  ' Chenchen Miao',\n",
       "  ' Zhenzhao Tao',\n",
       "  ' Zhichen Pan',\n",
       "  ' Pei Wang',\n",
       "  ' Xin Zheng',\n",
       "  ' Xiaodan Deng Zhijie Liu',\n",
       "  ' Xiaoyao Xie',\n",
       "  ' Xuhong Yu',\n",
       "  ' Shanping You',\n",
       "  ' Hui Zhang (FAST Collaboration)    '],\n",
       " ['Jun Liu'],\n",
       " ['Jack Murtagh', ' Omer Reingold', ' Aaron Sidford', ' Salil Vadhan'],\n",
       " ['Ruochen Xu', ' Tao Ge', ' Furu Wei'],\n",
       " ['Jiaxin Xie', ' Zhiqiang Xu'],\n",
       " ['Euijoon Ahn',\n",
       "  ' Ashnil Kumar',\n",
       "  ' Dagan Feng',\n",
       "  ' Michael Fulham',\n",
       "  ' Jinman Kim'],\n",
       " ['Ruiqin Zhao',\n",
       "  ' Hao Long',\n",
       "  ' Octavia A. Dobre',\n",
       "  ' Xiaohong Shen',\n",
       "  ' Telex M. N. Ngatched',\n",
       "  ' Haodi Mei'],\n",
       " ['Yitong Li',\n",
       "  ' Michael Murias',\n",
       "  ' Samantha Major',\n",
       "  ' Geraldine Dawson',\n",
       "  ' David E. Carlson'],\n",
       " ['Nancy Rodriguez', ' Michael Winkler'],\n",
       " ['Florian Beyer', ' Leon Escobar', ' Jörg Frauendiener', ' Joshua Ritchie'],\n",
       " ['Lei Qian',\n",
       "  ' Zhichen Pan',\n",
       "  ' Di Li',\n",
       "  ' George Hobbs',\n",
       "  ' Weiwei Zhu',\n",
       "  ' Pei Wang',\n",
       "  ' Zhijie Liu',\n",
       "  ' Youling Yue',\n",
       "  ' Yan Zhu',\n",
       "  ' Hongfei Liu',\n",
       "  ' Dongjun Yu',\n",
       "  ' Jinghai Sun',\n",
       "  ' Peng Jiang',\n",
       "  ' Gaofeng Pan',\n",
       "  ' Hui Li',\n",
       "  ' Hengqian Gan',\n",
       "  ' Rui Yao',\n",
       "  ' Xiaoyao Xie',\n",
       "  ' Fernando Camilo',\n",
       "  ' Andrew Cameron',\n",
       "  ' Lei Zhang',\n",
       "  ' Shen Wang',\n",
       "  ' FAST Project'],\n",
       " ['Luis Fernando Elizondo-Aguilera',\n",
       "  ' Ernesto Carlos Cortés-Morales',\n",
       "  ' Pablo F. Zubieta Rico',\n",
       "  ' Magdaleno Medina-Noyola',\n",
       "  ' Ramón Castañeda-Priego',\n",
       "  ' Thomas Voigtmann',\n",
       "  ' Gabriel Pérez-Ángel'],\n",
       " ['Zdenek Sekanina'],\n",
       " ['Anders Hildeman', ' David Bolin', ' Igor Rychlik'],\n",
       " ['Ian Goodfellow'],\n",
       " ['Kiichi Watanabe',\n",
       "  ' Yuto Nakashima',\n",
       "  ' Shunsuke Inenaga',\n",
       "  ' Hideo Bannai',\n",
       "  ' Masayuki Takeda'],\n",
       " ['Noriki Fujisato',\n",
       "  ' Yuto Nakashima',\n",
       "  ' Shunsuke Inenaga',\n",
       "  ' Hideo Bannai',\n",
       "  ' Masayuki Takeda'],\n",
       " ['Peng Ding', ' Fan Li'],\n",
       " ['Gladys Hilasaca', ' Fernando V. Paulovich']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Training complex machine learning models in parallel is an increasingly\\nimportant workload. We accelerate distributed parallel training by designing a\\ncommunication primitive that uses a programmable switch dataplane to execute a\\nkey step of the training process. Our approach, SwitchML, reduces the volume of\\nexchanged data by aggregating the model updates from multiple workers in the\\nnetwork. We co-design the switch processing with the end-host protocols and ML\\nframeworks to provide a robust, efficient solution that speeds up training by\\nup to 300%, and at least by 20% for a number of real-world benchmark models.\\n',\n",
       " 'In the monitoring of a complex electric grid, it is of paramount importance\\nto provide operators with early warnings of anomalies detected on the network,\\nalong with a precise classification and diagnosis of the specific fault type.\\nIn this paper, we propose a novel multi-stage early warning system prototype\\nfor electric grid fault detection, classification, subgroup discovery, and\\nvisualization. In the first stage, a computationally efficient anomaly\\ndetection method based on quartiles detects the presence of a fault in real\\ntime. In the second stage, the fault is classified into one of nine pre-defined\\ndisaster scenarios. The time series data are first mapped to highly\\ndiscriminative features by applying dimensionality reduction based on temporal\\nautocorrelation. The features are then mapped through one of three\\nclassification techniques: support vector machine, random forest, and\\nartificial neural network. Finally in the third stage, intra-class clustering\\nbased on dynamic time warping is used to characterize the fault with further\\ngranularity. Results on the Bonneville Power Administration electric grid data\\nshow that i) the proposed anomaly detector is both fast and accurate; ii)\\ndimensionality reduction leads to dramatic improvement in classification\\naccuracy and speed; iii) the random forest method offers the most accurate,\\nconsistent, and robust fault classification; and iv) time series within a given\\nclass naturally separate into five distinct clusters which correspond closely\\nto the geographical distribution of electric grid buses.\\n',\n",
       " 'In the big data era of observational oceanography, passive acoustics datasets\\nare becoming too high volume to be processed on local computers due to their\\nprocessor and memory limitations. As a result there is a current need for our\\ncommunity to turn to cloud-based distributed computing. In this paper we\\npresent a scalable computation chain for FFT (Fast Fourier Transform)-based\\nfeatures (e.g., Power Spectral Density) based on the Apache frameworks Hadoop\\nand Spark. These features are at the core of many different types of acoustic\\nanalysis where the need of processing data at scale with speed is evident, e.g.\\nserving as long-term averaged learning representations of soundscapes to\\nidentify periods of acoustic interest. In addition to a complete description of\\nour system implementation, we also provide a computational benchmark comparing\\nour system to different programming languages (Matlab, Python) in standalone\\nexecutions, and evaluate its scalability using the speed up metric. Our current\\nresults show that our system obtains near-linear scalability in its distributed\\nconfiguration for ou tested dataset, and more surprisingly, is even slightly\\nmore performant with equivalent Matlab and Python-based workflows when executed\\non a single node.\\n',\n",
       " 'We demonstrate a measure for the effective number of parameters constrained\\nby a posterior distribution in the context of cosmology. In the same way that\\nthe mean of the Shannon information (i.e. the Kullback-Leibler divergence)\\nprovides a measure of the strength of constraint between prior and posterior,\\nwe show that the variance of the Shannon information gives a measure of\\ndimensionality of constraint. We examine this quantity in a cosmological\\ncontext, applying it to likelihoods derived from Cosmic Microwave Background,\\nlarge scale structure and supernovae data. We show that this measure of\\nBayesian model dimensionality compares favourably both analytically and\\nnumerically in a cosmological context with the existing measure of model\\ncomplexity used in the literature.\\n',\n",
       " 'Scaling CNN training is necessary to keep up with growing datasets and reduce\\ntraining time. We also see an emerging need to handle datasets with very large\\nsamples, where memory requirements for training are large. Existing training\\nframeworks use a data-parallel approach that partitions samples within a\\nmini-batch, but limits to scaling the mini-batch size and memory consumption\\nmakes this untenable for large samples. We describe and implement new\\napproaches to convolution, which parallelize using spatial decomposition or a\\ncombination of sample and spatial decomposition. This introduces many\\nperformance knobs for a network, so we develop a performance model for CNNs and\\npresent a method for using it to automatically determine efficient\\nparallelization strategies.\\nWe evaluate our algorithms with microbenchmarks and image classification with\\nResNet-50. Our algorithms allow us to prototype a model for a mesh-tangling\\ndataset, where sample sizes are very large. We show that our parallelization\\nachieves excellent strong and weak scaling and enables training for previously\\nunreachable datasets.\\n',\n",
       " 'To move upwind, sailing vessels have to cross the wind by tacking. During\\nthis manoeuvre distance made good may be lost and especially smaller vessels\\nmay struggle to complete a tack in averse wind and wave conditions. A decision\\nfor the best tack manoeuvre needs to be made based on weather and available\\ntack implementations.\\nThis paper develops an adaptive probabilistic tack manoeuvre decision method.\\nThe order of attempting different tacking strategies is based on previous\\nsuccess within a timeout, combined with an exploration component. This method\\nis successfully demonstrated on the 1m long sailing vessel Black Python. Four\\nstrategies for crossing the wind were evaluated through adaptive probabilistic\\nchoices, and the best was identified without detailed sensory knowledge of the\\nactual weather conditions.\\nBased on the positive results, further improvements for a better selection\\nprocess are suggested and the potential of using the collected data to\\nrecognise the impact of weather conditions on tacking efforts is recognised.\\n',\n",
       " 'Large scale electronic health records (EHRs) present an opportunity to\\nquickly identify suitable individuals in order to directly invite them to\\nparticipate in an observational study. EHRs can contain data from millions of\\nindividuals, raising the question of how to optimally select a cohort of size n\\nfrom a larger pool of size N. In this paper we propose a simple selective\\nrecruitment protocol that selects a cohort in which covariates of interest tend\\nto have a uniform distribution. We show that selectively recruited cohorts\\npotentially offer greater statistical power and more accurate parameter\\nestimates than randomly selected cohorts. Our protocol can be applied to\\nstudies with multiple categorical and continuous covariates. We apply our\\nprotocol to a numerically simulated prospective observational study using an\\nEHR database of stable acute coronary disease patients from 82,089 individuals\\nin the U.K. Selective recruitment designs require a smaller sample size,\\nleading to more efficient and cost-effective studies.\\n',\n",
       " \"Control charts have traditionally been used in industrial statistics, but are\\nconstantly seeing new areas of application, especially in the age of Industry\\n4.0. This paper introduces a new method, which is suitable for applications in\\nthe healthcare sector, especially for monitoring a health-characteristic of a\\npatient. We adapt a Markov chain-based approach and develop a method in which\\nnot only the shift size (i.e. the degradation of the patient's health) can be\\nrandom, but the effect of the repair (i.e. treatment) and time between\\nsamplings (i.e. visits) too. This means that we do not use many often-present\\nassumptions which are usually not applicable for medical treatments. The\\naverage cost of the protocol, which is determined by the time between samplings\\nand the control limit, can be estimated using the stationary distribution of\\nthe Markov chain.\\nFurthermore, we incorporate the standard deviation of the cost into the\\noptimisation procedure, which is often very important from a process control\\nviewpoint. The sensitivity of the optimal parameters and the resulting average\\ncost and cost standard deviation on different parameter values is investigated.\\nWe demonstrate the usefulness of the approach for real-life data of patients\\ntreated in Hungary: namely the monitoring of cholesterol level of patients with\\ncardiovascular event risk. The results showed that the optimal parameters from\\nour approach can be somewhat different from the original medical parameters.\\n\",\n",
       " 'A standard approach to study time-dependent stochastic processes is the power\\nspectral density (PSD), an ensemble-averaged property defined as the Fourier\\ntransform of the autocorrelation function of the process in the asymptotic\\nlimit of long observation times, $T\\\\to\\\\infty$. In many experimental situations\\none is able to garner only relatively few stochastic time series of finite $T$,\\nsuch that practically neither an ensemble average nor the asymptotic limit\\n$T\\\\to\\\\infty$ can be achieved. To accommodate for a meaningful analysis of such\\nfinite-length data we here develop the framework of single-trajectory spectral\\nanalysis for one of the standard models of anomalous diffusion, scaled Brownian\\nmotion. We demonstrate that the frequency dependence of the single-trajectory\\nPSD is exactly the same as for standard Brownian motion, which may lead one to\\nthe erroneous conclusion that the observed motion is normal-diffusive. However,\\na distinctive feature is shown to be provided by the explicit dependence on the\\nmeasurement time $T$, and this ageing phenomenon can be used to deduce the\\nanomalous diffusion exponent. We also compare our results to the\\nsingle-trajectory PSD behaviour of another standard anomalous diffusion\\nprocess, fractional Brownian motion, and work out the commonalities and\\ndifferences. Our results represent an important step in establishing\\nsingle-trajectory PSDs as an alternative (or complement) to analyses based on\\nthe time-averaged mean squared displacement.\\n',\n",
       " 'Two main methods for exploring patterns in data are data visualization and\\nmachine learning. The former relies on humans for investigating the patterns\\nwhile the latter relies on machine learning algorithms. This paper tries to\\nfind the patterns using only data visualization. It addresses the mystery of\\npopulation decline of a bird, named Rose-Crested Blue Pipit, in a hypothetical\\nnature preserve. Different visualization techniques are used and the reasons of\\nthe problem are found and categorized. Finally, the solutions for preventing\\nthe future similar problems are suggested. This paper can be useful for getting\\nintroduced to some data visualization tools and techniques.\\n',\n",
       " 'In the present paper will be discussed the problem related to the individual\\nhousehold electric power consumption of objects in different areas-industry,\\nfarmers, banks, hospitals, theaters, hostels, supermarkets, universities. The\\nmain goal of the directed research is to estimate the active P and full S power\\nconsumptions for all studied buildings. The defined goal is achieved by solving\\nof the following three problems. The first problem studies which buildings\\nincrease their power consumption. The second one finds which objects have the\\ngreatest increase of power consumption. And the third problem regards if it is\\npossible to make a short-term forecast, based on the solutions of previous two\\nproblems. The present research and solving of the aforementioned problems is\\nconducted using fractional Brownian motion theory. The applicability of this\\napproach is illustrated on the example with 20 real objects in different areas.\\nThe paper ends with conclusion notes about possibilities to make short-term\\nforecasts about power consumption of the considered buildings.\\n',\n",
       " 'Illegal wildlife poaching threatens ecosystems and drives endangered species\\ntoward extinction. However, efforts for wildlife monitoring and protection in\\nconservation areas are constrained by the limited resources of law enforcement\\nagencies. To aid in wildlife protection, PAWS is an ML pipeline that has been\\ndeveloped as an end-to-end, data-driven approach to combat illegal poaching.\\nPAWS assists park managers by identifying areas at high risk of poaching\\nthroughout protected areas based on real-world data and generating optimal\\npatrol routes for deployment in the field. In this paper, we address\\nsignificant challenges including extreme class imbalance (up to 1:200), bias,\\nand uncertainty in wildlife poaching data to enhance PAWS and apply its\\nmethodology to several national parks with diverse characteristics. (i) We use\\nGaussian processes to quantify predictive uncertainty, which we exploit to\\nincrease the robustness of our prescribed patrols. We evaluate our approach on\\nreal-world historic poaching data from Murchison Falls and Queen Elizabeth\\nNational Parks in Uganda and, for the first time, Srepok Wildlife Sanctuary in\\nCambodia. (ii) We present the results of large-scale field tests conducted in\\nMurchison Falls and Srepok Wildlife Sanctuary which confirm that the predictive\\npower of PAWS extends promisingly to multiple parks. This paper is part of an\\neffort to expand PAWS to 600 parks around the world through integration with\\nSMART conservation software.\\n',\n",
       " \"Global fire activity has a huge impact on human lives. In recent years, many\\nfire models have been developed to forecast fire activity. They present good\\nresults for some regions but require complex parametrizations and input\\nvariables that are not easily obtained or estimated. In this paper, we evaluate\\nthe possibility of using historical data from 2003 to 2017 of active fire\\ndetections (NASA's MODIS MCD14ML C6) and time series forecasting methods to\\nestimate global fire season severity (FSS), here defined as the accumulated\\nfire detections in a season. We used a hexagonal grid to divide the globe, and\\nwe extracted time series of daily fire counts from each cell. We propose a\\nstraightforward method to estimate the fire season lengths. Our results show\\nthat in 99% of the cells, the fire seasons have lengths shorter than seven\\nmonths. Given this result, we extracted the fire seasons defined as time\\nwindows of seven months centered in the months with the highest fire\\noccurrence. We define fire season severity (FSS) as the accumulated fire\\ndetections in a season. A trend analysis suggests a global decrease in length\\nand severity. Since FSS time series are concise, we used the\\nmonthly-accumulated fire counts (MA-FC) to train and test the seven forecasting\\nmodels. Results show low forecasting errors in some areas. Therefore we\\nconclude that many regions present predictable variations in the FSS.\\n\",\n",
       " 'The battle of Kursk between Soviet and German is known to be the biggest tank\\nbattle in the history. The present paper uses the tank and artillery data from\\nthe Kursk database for fitting both forms of homogeneous and heterogeneous\\nLanchester model. Under homogeneous form the Soviet (or German) tank casualty\\nis attributed to only the German(or Soviet) tank engagement. For heterogeneous\\nform the tank casualty is attributed to both tank and artillery engagements. A\\nset of differential equations using both forms have been developed, and the\\ncommonly used least square estimation is compared with maximum likelihood\\nestimation for attrition rates and exponent coefficients. For validating the\\nmodels, different goodness-of-fit measures like R2, sum-of-square-residuals\\n(SSR), root-mean-square error (RMSE), Kolmogorov-Smirnov (KS) and chi-square\\nstatistics are used for comparison. Numerical results suggest the model is\\nstatistically more accurate when each day of the battle is considered as a\\nmini-battle. The distribution patterns of the SSR and likelihood values with\\nvarying parameters are represented using contour plots and 3D surfaces.\\n',\n",
       " 'Generalized Berwald manifolds are Finsler manifolds admitting linear\\nconnections such that the parallel transports preserve the Finslerian length of\\ntangent vectors. By the fundamental result of the theory \\\\cite{V5} such a\\nlinear connection must be metrical with respect to the averaged Riemannian\\nmetric given by integration of the Riemann-Finsler metric on the indicatrix\\nhypersurfaces. Therefore the linear connection is uniquely determined by its\\ntorsion tensor. If the torsion is zero then we have a classical Berwald\\nmanifolds. Otherwise the torsion is a strange data we need to express in terms\\nof quantities of the Finsler manifold. In the paper we are going to give\\nexplicit formulas for the linear connections with totally anti-symmetric\\ntorsion tensor of three-dimensional generalized Berwald manifolds. The results\\nare based on averaging of (intrinsic) Finslerian quantities by integration over\\nthe indicatrix surfaces. They imply some consequences for the base manifold as\\na Riemannian space with respect to the averaged Riemannian metric. The possible\\ncases are Riemannian spaces of constant zero curvature, constant positive\\ncurvature or Riemannian spaces admitting Killing vector fields of constant\\nRiemannian length.\\n',\n",
       " 'This paper looks into the problem of detecting network anomalies by analyzing\\nNetFlow records. While many previous works have used statistical models and\\nmachine learning techniques in a supervised way, such solutions have the\\nlimitations that they require large amount of labeled data for training and are\\nunlikely to detect zero-day attacks. Existing anomaly detection solutions also\\ndo not provide an easy way to explain or identify attacks in the anomalous\\ntraffic. To address these limitations, we develop and present GEE, a framework\\nfor detecting and explaining anomalies in network traffic. GEE comprises of two\\ncomponents: (i) Variational Autoencoder (VAE) - an unsupervised deep-learning\\ntechnique for detecting anomalies, and (ii) a gradient-based fingerprinting\\ntechnique for explaining anomalies. Evaluation of GEE on the recent UGR dataset\\ndemonstrates that our approach is effective in detecting different anomalies as\\nwell as identifying fingerprints that are good representations of these various\\nattacks.\\n',\n",
       " \"We construct the mean thermal Sunyaev-Zel'dovich (tSZ) Comptonization y\\nprofile around Luminous Red Galaxies (LRGs) in the redshift range 0.16 < z <\\n0.47 from the Sloan Digital Sky Survey (SDSS) Data Release 7 (DR7) using the\\nPlanck y map. The mean central tSZ signal for the full sample is y ~ 1.8 *\\n10^(-7) and we detect tSZ emission out to ~30 arcmin, which is well beyond the\\n10 arcmin angular resolution of the y map and well beyond the virial radii of\\nthe LRGs. We compare the measured profile with predictions from the cosmo-OWLS\\nsuite of cosmological hydrodynamical simulations. This comparison agrees well\\nfor models that include feedback from active galactic nuclei (AGN), but not\\nwith hydrodynamic models without this energetic feedback mechanism. This\\nsuggests that an additional heating mechanism is required over SNe feedback and\\nstar formation to explain the y data profile. We also compare our results with\\npredictions based on the halo model with a universal pressure profile (UPP)\\ngiving the y signal. The predicted profile is consistent with the data, but\\nonly if we account for the clustering of haloes via a two-halo term and if halo\\nmasses are estimated using the mean stellar-to-halo mass (SHM) relation of\\nCoupon et al. (2015) or Wang et al.(2016) estimated from gravitational lensing\\nmeasurements. We also discuss the importance of scatter in the SHM relation on\\nthe model predictions.\\n\",\n",
       " \"At leading-twist accuracy the form factors for the transitions from a virtual\\nphoton to the $\\\\eta$ or $\\\\eta'$ can be expanded into a power series of the\\nvariable $\\\\omega$, being related to the difference of two photon virtualities.\\nThe series possess the remarkable feature that only the Gegenbauer coefficients\\nof the meson distribution amplitudes of order $l\\\\leq m$ contribute to the term\\n$\\\\sim \\\\omega^m$. Thus, for $\\\\omega\\\\to 0$ only the asymptotic meson distribution\\namplitude contributes, allowing for a test of the mixing of the $\\\\eta$ and\\n$\\\\eta'$ decay constants. Employing the Gegenbauer coefficients determined in\\nanalysis of the form factors in the real photon limit, we present predictions\\nfor the $\\\\gamma^*\\\\eta$ and $\\\\gamma^*\\\\eta'$ form factors and compare them to the\\nBaBar data.\\n\",\n",
       " \"As cost and performance benefits associated with Moore's Law scaling slow,\\nresearchers are studying alternative architectures (e.g., based on analog\\nand/or spiking circuits) and/or computational models (e.g., convolutional and\\nrecurrent neural networks) to perform application-level tasks faster, more\\nenergy efficiently, and/or more accurately. We investigate cellular neural\\nnetwork (CeNN)-based co-processors at the application-level for these metrics.\\nWhile it is well-known that CeNNs can be well-suited for spatio-temporal\\ninformation processing, few (if any) studies have quantified the\\nenergy/delay/accuracy of a CeNN-friendly algorithm and compared the CeNN-based\\napproach to the best von Neumann algorithm at the application level. We present\\nan evaluation framework for such studies. As a case study, a CeNN-friendly\\ntarget-tracking algorithm was developed and mapped to an array architecture\\ndeveloped in conjunction with the algorithm. We compare the energy, delay, and\\naccuracy of our architecture/algorithm (assuming all overheads) to the most\\naccurate von Neumann algorithm (Struck). Von Neumann CPU data is measured on an\\nIntel i5 chip. The CeNN approach is capable of matching the accuracy of Struck,\\nand can offer approximately 1000x improvements in energy-delay product.\\n\",\n",
       " 'Energy efficiency in a data center is a challenge and has garnered\\nresearchers interest. In this paper we address the energy efficiency issue of a\\nsmall scale data center by utilizing Single Board Computer (SBC) based\\nclusters. A compact design layout is presented to build two clusters using 20\\nnodes each. Extensive testing was carried out to analyze the performance of\\nthese clusters using popular performance benchmarks for task execution time,\\nmemory/storage utilization, network throughput and energy consumption. Further,\\nwe investigate the cost of operating SBC based clusters by correlating energy\\nutilization for the execution time of various benchmarks using workloads of\\ndifferent sizes. Results show that, although the low-cost benefit of a cluster\\nbuilt with ARM-based SBCs is desirable, these clusters yield low comparable\\nperformance and energy efficiency due to limited onboard capabilities. It is\\npossible to tweak Hadoop configuration parameters for an ARM-based SBC cluster\\nto efficiently utilize resources. We present, a discussion on the effectiveness\\nof the SBC-based clusters as a testbed for inexpensive and green cloud\\ncomputing research.\\n',\n",
       " \"This paper introduces and evaluates the GestureKeeper, a robust hand-gesture\\nrecognition system based on a wearable inertial measurements unit (IMU). The\\nidentification of the time windows where the gestures occur, without relying on\\nan explicit user action or a special gesture marker, is a very challenging\\ntask. To address this problem, GestureKeeper identifies the start of a gesture\\nby exploiting the underlying dynamics of the associated time series using a\\nrecurrence quantification analysis (RQA). RQA is a powerful method for\\nnonlinear time-series analysis, which enables the detection of critical\\ntransitions in the system's dynamical behavior. Most importantly, it does not\\nmake any assumption about the underlying distribution or model that governs the\\ndata. Having estimated the gesture window, a support vector machine is employed\\nto recognize the specific gesture. Our proposed method is evaluated by means of\\na small-scale pilot study at FORTH and demonstrated that GestureKeeper can\\nidentify correctly the start of a gesture with a 87\\\\% mean balanced accuracy\\nand classify correctly the specific hand-gesture with a mean accuracy of over\\n96\\\\%. To the best of our knowledge, GestureKeeper is the first automatic\\nhand-gesture identification system based only on accelerometer. The performance\\nanalysis reveals the predictive power of the features and the system's\\nrobustness in the presence of additive noise. We also performed a sensitivity\\nanalysis to examine the impact of various parameters and a comparative analysis\\nof different classifiers (SVM, random forests). Most importantly, the system\\ncan be extended to incorporate a large dictionary of gestures and operate\\nwithout further calibration for a new user.\\n\",\n",
       " \"Social networks have become in the last decade central to political life.\\nHowever, to those interested in analysing the communication strategies of\\nparties and candidates at election time, the introduction of the Internet into\\nthe political sphere has proved a mixed blessing. Indeed, while retrieving,\\nconsulting, and archiving original documents pertaining to a specific campaign\\nhave become easier, faster, and achievable on a larger scale, thus opening up a\\npromising El Dorado for research in this area, studying online campaigns has\\nalso inevitably introduced new technical, methodological and legal challenges\\nwhich have turned out to be increasingly complex for academics in the\\nhumanities and social sciences to solve on their own.This paper therefore\\nproposes to provide feedback on experience and experimental validation from a\\nmultidisciplinary project called POLIWEB devoted to the comparative analysis of\\npolitical campaigns on social media in the run up to the 2014 elections to the\\nEuropean Parliament in France and in the United Kingdom. Together with\\nobservations from a humanities' perspective on issues related to such a\\nproject, this paper also presents experimental results concerning three of the\\ndata collection life cycle phases: collection, cleaning, and storage. The\\noutcome is a data collection ready to be analysed for various purposes meant to\\naddress the political science topic under consideration.\\n\",\n",
       " 'Recent work has identified that classification models implemented as neural\\nnetworks are vulnerable to data-poisoning and Trojan attacks at training time.\\nIn this work, we show that these training-time vulnerabilities extend to deep\\nreinforcement learning (DRL) agents and can be exploited by an adversary with\\naccess to the training process. In particular, we focus on Trojan attacks that\\naugment the function of reinforcement learning policies with hidden behaviors.\\nWe demonstrate that such attacks can be implemented through minuscule data\\npoisoning (as little as 0.025% of the training data) and in-band reward\\nmodification that does not affect the reward on normal inputs. The policies\\nlearned with our proposed attack approach perform imperceptibly similar to\\nbenign policies but deteriorate drastically when the Trojan is triggered in\\nboth targeted and untargeted settings. Furthermore, we show that existing\\nTrojan defense mechanisms for classification tasks are not effective in the\\nreinforcement learning setting.\\n',\n",
       " 'The International Virtual Observatory Alliance (IVOA) held its bi-annual\\nInteroperability Meeting over two and half days prior to the ADASS 2018\\nconference. We provide a brief report on the status of the IVOA and the\\nactivities of the Interoperability Meeting held in College Park.\\n',\n",
       " \"We write in response to the call from the 2020 Decadal Survey to submit white\\npapers illustrating the most pressing scientific questions in astrophysics for\\nthe coming decade. We propose exploration as the central question for the\\nDecadal Committee's discussions.The history of astronomy shows that paradigm\\nchanging discoveries are not driven by well formulated scientific questions,\\nbased on the knowledge of the time. They were instead the result of the\\nincrease in discovery space fostered by new telescopes and instruments. An\\nadditional tool for increasing the discovery space is provided by the analysis\\nand mining of the increasingly larger amount of archival data available to\\nastronomers. Revolutionary observing facilities, and the state of the art\\nastronomy archives needed to support these facilities, will open up the\\nuniverse to new discovery. Here we focus on exploration for compact objects and\\nmulti messenger science. This white paper includes science examples of the\\npower of the discovery approach, encompassing all the areas of astrophysics\\ncovered by the 2020 Decadal Survey.\\n\",\n",
       " \"Optimal capital allocation between different assets is an important financial\\nproblem, which is generally framed as the portfolio optimization problem.\\nGeneral models include the single-period and multi-period cases. The\\ntraditional Mean-Variance model introduced by Harry Markowitz has been the\\nbasis of many models used to solve the portfolio optimization problem. The\\noverall goal is to achieve the highest return and lowest risk in portfolio\\noptimization problems. In this paper, we will present an optimal portfolio\\nbased the Markowitz Mean-Variance-Skewness with weight constraints model for\\nshort-term investment opportunities in Iran's stock market. We will use a\\nneural network based predictor to predict the stock returns and measure the\\nrisk of stocks based on the prediction errors in the neural network. We will\\nperform a series of experiments on our portfolio optimization model with the\\nreal data from Iran's stock market indices including Bank, Insurance,\\nInvestment, Petroleum Products and Chemicals indices. Finally, 8 different\\nportfolios with low, medium and high risks for different type of investors\\n(risk-averse or risk taker) using genetic algorithm will be designed and\\nanalyzed.\\n\",\n",
       " \"GPU (graphics processing unit) has been used for many data-intensive\\napplications. Among them, deep learning systems are one of the most important\\nconsumer systems for GPU nowadays. As deep learning applications impose deeper\\nand larger models in order to achieve higher accuracy, memory management\\nbecomes an important research topic for deep learning systems, given that GPU\\nhas limited memory size. Many approaches have been proposed towards this issue,\\ne.g., model compression and memory swapping. However, they either degrade the\\nmodel accuracy or require a lot of manual intervention. In this paper, we\\npropose two orthogonal approaches to reduce the memory cost from the system\\nperspective. Our approaches are transparent to the models, and thus do not\\naffect the model accuracy. They are achieved by exploiting the iterative nature\\nof the training algorithm of deep learning to derive the lifetime and\\nread/write order of all variables. With the lifetime semantics, we are able to\\nimplement a memory pool with minimal fragments. However, the optimization\\nproblem is NP-complete. We propose a heuristic algorithm that reduces up to\\n13.3% of memory compared with Nvidia's default memory pool with equal time\\ncomplexity. With the read/write semantics, the variables that are not in use\\ncan be swapped out from GPU to CPU to reduce the memory footprint. We propose\\nmultiple swapping strategies to automatically decide which variable to swap and\\nwhen to swap out (in), which reduces the memory cost by up to 34.2% without\\ncommunication overhead.\\n\",\n",
       " 'We consider the Cahn-Hilliard equation on manifolds with conical\\nsingularities. For appropriate initial data we show that the solution exists in\\nthe maximal $L^q$-regularity space for all times and becomes instantaneously\\nsmooth in space and time, where the maximal $L^q$-regularity is obtained in the\\nsense of Mellin-Sobolev spaces. Moreover, we provide precise information\\nconcerning the asymptotic behavior of the solution close to the conical tips in\\nterms of the local geometry.\\n',\n",
       " 'For the estimation of a new energy supply system it is an important to have\\nhigh-resolution energy load profile. Such a profile is in general either not\\npresent or very costly to obtain. We will therefore present a method which\\nsynthesizes load profiles from minimal given data, but with maximal resolution.\\nThe general initial data setting includes month integrals and load profiles a\\nfew days. The resulting time series features all important properties to\\nrepresent a real energy profile.\\n',\n",
       " 'The study of accurate methods to estimate the distribution of stellar\\nrotational velocities is important for understanding many aspects of stellar\\nevolution. From such observations we obtain the projected rotational speed v\\nsin(i) in order to recover the true distribution of the rotational velocity. To\\nthat end, we need to solve a difficult inverse problem that can be posed as a\\nFredholm integral of the first kind. n this work we have used a novel approach\\nbased on Maximum likelihood (ML) estimation to obtain an approximation of the\\ntrue rotational velocity probability density function expressed as a sum of\\nknown distribution families. In our proposal, the measurements have been\\ntreated as random variables drawn from the projected rotational velocity\\nprobability density function. We analyzed the case of Maxwellian sum\\napproximation, where we estimated the parameters that define the sum of\\ndistributions. The performance of the proposed method is analyzed using Monte\\nCarlo simulations considering two theoretical cases for the probability density\\nfunction of the true rotational stellar velocities: i) an unimodal Maxwellian\\nprobability density distribution and ii) a bimodal Maxwellian probability\\ndensity distribution. The results show that the proposed method yielded more\\naccurate estimates in comparison with the Tikhonov regularization method,\\nespecially for small sample length N=50. Our proposal was evaluated using real\\ndata from three sets of measurements, and our findings were validated using\\nthree statistical tests. The ML approach with Maxwellian sum approximation is a\\naccurate method to deconvolve the rotational velocity probability density\\nfunction, even when the sample length is small (N= 50)\\n',\n",
       " 'The analysis and combination of data from different gamma-ray instruments\\ninvolves the use of collaboration proprietary software and case-by-case\\nmethods. The effort of defining a common data format for high-level data,\\nnamely event lists and instrument response functions (IRFs), has recently\\nstarted for very-high-energy gamma-ray instruments, driven by the upcoming\\nCherenkov Telescope Array (CTA). In this work we implemented this prototypical\\ndata format for a small set of MAGIC, VERITAS, FACT, and H.E.S.S. Crab nebula\\nobservations, and we analyzed them with the open-source gammapy software\\npackage. By combining data from $Fermi$-LAT, and from four of the currently\\noperating imaging atmospheric Cherenkov telescopes, we produced a joint maximum\\nlikelihood fit of the Crab nebula spectrum. Aspects of the statistical errors\\nand the evaluation of systematic uncertainty are also commented upon, along\\nwith the release format of spectral measurements. The results presented in this\\nwork are obtained using open-access on-line assets that allow for a long-term\\nreproducibility of the results.\\n',\n",
       " \"Analyzing mismatch in supply and demand of taxis is an important effort to\\nunderstand passengers' demand. In this paper, we have analyzed the effect of\\nrain on the demand for yellow taxis in city-wide as well as in a point of\\ninterest in New York City. Because a pickup event is a realized demand, we\\nstudied empty travel time, the number of pickups per driver, the average amount\\nof income per drive indices to infer demand from taxis data of 2013. Findings\\nhighlight that the higher demand exists because of many short-trips during the\\nrain. This paper illustrates the change in passengers' demand increased by the\\nonset of weather condition.\\n\",\n",
       " 'We present high-quality CCD photometry in the Washington system C and T1\\npassbands down to T1 ~ 19.5 mag in the fields of 10 Galactic open clusters\\n(OCs) or candidates projected close to the Galactic plane, namely: ESO\\n313-SC03, BH 54, Ruprecht 87, ESO 129-SC32, BH 217, Collinder 347, Basel 5,\\nRuprecht 144, Archinal 1 and Berkeley 82. Four of these objects are located\\ntoward the Galactic centre direction within a solid angle of 21 deg. No\\nphotoelectric or CCD photometry in the optical domain has been so far reported\\nfor five of these objects. Cluster radii are estimated from radial density\\nprofiles (RDPs) in the cluster fields. Using the cluster Washington (C-T1,T1)\\ncolour-magnitude diagrams (CMDs), statistically cleaned from field star\\ncontamination, we estimate reddening, heliocentric distance and age of the\\nclusters by fitting Padova theoretical isochrones computed for the Washington\\nsystem. In all cases, the best fittings were obtained with nearly solar metal\\ncontent isochrones. Both RDPs and CMDs show that we are dealing with real OCs,\\nexcept for Ruprecht 87 and Archinal\\\\,1 that are found to be probably not\\nphysical systems. Differential reddening appears to be present across the\\nfields of ESO313-SC03, ESO129-SC32, BH 217, Collinder 347 and Basel 5. The\\nstudied OCs are located at d = 1.0-5.0 kpc from the Sun and at Galactocentric\\ndistances R_GC = 6.0-10.6 kpc, with mean reddening E(B-V) in the range\\n0.10-1.30 mag and ages between 5 Myr (Collinder 347) and ~ 1000 Myr (Basel 5).\\nThe estimated linear cluster radii are in the range of 0.4-3.2 pc. In general\\nterms, the results obtained show fairly good agreement with previous\\nphotometric results. In some clusters, however, considerable differences are\\nfound between the present results and previous ones determined using\\nnear-infrared photometric data. The current study provides new OC parameters\\nand some revisions to the OC catalogues.\\n',\n",
       " 'We present and evaluate the application of the \"Reconstructed Image from\\nSimulations Ensemble\" (RISE), a novel tomographic image reconstruction method,\\nin infrared tomography. We demonstrate that established methods of photon\\nemission tomography, widely used with penetrating ionizing radiation, are\\napplicable to infrared radiation. RISE, the method of choice, employs\\nstatistical physics concepts and utilizes Monte Carlo techniques to construct\\nthe imaged object from its infrared planar projections. The validity of the\\nInfraRed Emission Tomographic (IRET) method is demonstrated, and the efficacy\\nof RISE is evaluated with A) simulated data and B) experimental sets of\\ninfrared projections obtained from a thermal phantom with an infrared camera.\\nFor the simulation studies presented, the reconstructed images obtained with\\nRISE and the well - known Algebraic Reconstruction Technique (ART) and Maximum\\nLikelihood Expectation Maximization (MLEM) method were evaluated using\\nwell-established metrics.\\n',\n",
       " 'This paper explores the problem of matching entities across different\\nknowledge graphs. Given a query entity in one knowledge graph, we wish to find\\nthe corresponding real-world entity in another knowledge graph. We formalize\\nthis problem and present two large-scale datasets for this task based on\\nexiting cross-ontology links between DBpedia and Wikidata, focused on several\\nhundred thousand ambiguous entities. Using a classification-based approach, we\\nfind that a simple multi-layered perceptron based on representations derived\\nfrom RDF2Vec graph embeddings of entities in each knowledge graph is sufficient\\nto achieve high accuracy, with only small amounts of training data. The\\ncontributions of our work are datasets for examining this problem and strong\\nbaselines on which future work can be based.\\n',\n",
       " \"The Magnetospheric Multiscale (MMS) mission has given us unprecedented access\\nto high cadence particle and field data of magnetic reconnection at Earth's\\nmagnetopause. MMS first passed very near an X-line on 16 October 2015, the\\nBurch event, and has since observed multiple X-line crossings. Subsequent 3D\\nparticle-in-cell (PIC) modeling efforts of and comparison with the Burch event\\nhave revealed a host of novel physical insights concerning magnetic\\nreconnection, turbulence induced particle mixing, and secondary instabilities.\\nIn this study, we employ the Gkeyll simulation framework to study the Burch\\nevent with different classes of extended, multi-fluid magnetohydrodynamics\\n(MHD), including models that incorporate important kinetic effects, such as the\\nelectron pressure tensor, with physics-based closure relations designed to\\ncapture linear Landau damping. Such fluid modeling approaches are able to\\ncapture different levels of kinetic physics in global simulations and are\\ngenerally less costly than fully kinetic PIC. We focus on the additional\\nphysics one can capture with increasing levels of fluid closure refinement via\\ncomparison with MMS data and existing PIC simulations.\\n\",\n",
       " \"This work studies the robustness certification problem of neural network\\nmodels, which aims to find certified adversary-free regions as large as\\npossible around data points. In contrast to the existing approaches that seek\\nregions bounded uniformly along all input features, we consider non-uniform\\nbounds and use it to study the decision boundary of neural network models. We\\nformulate our target as an optimization problem with nonlinear constraints.\\nThen, a framework applicable for general feedforward neural networks is\\nproposed to bound the output logits so that the relaxed problem can be solved\\nby the augmented Lagrangian method. Our experiments show the non-uniform bounds\\nhave larger volumes than uniform ones. Compared with normal models, the robust\\nmodels have even larger non-uniform bounds and better interpretability.\\nFurther, the geometric similarity of the non-uniform bounds gives a\\nquantitative, data-agnostic metric of input features' robustness.\\n\",\n",
       " 'In this paper we describe a fully-dynamic data structure for the planar point\\nlocation problem in the external memory model. Our data structure supports\\nqueries in $O(\\\\log_B n(\\\\log\\\\log_B n)^3))$ I/Os and updates in $O(\\\\log_B\\nn(\\\\log\\\\log_B n)^2))$ amortized I/Os, where $n$ is the number of segments in the\\nsubdivision and $B$ is the block size. This is the first dynamic data structure\\nwith almost-optimal query cost. For comparison all previously known results for\\nthis problem require $O(\\\\log_B^2 n)$ I/Os to answer queries. Our result almost\\nmatches the best known upper bound in the internal-memory model.\\n',\n",
       " 'Over the last years, the SWATH data-independent acquisition protocol\\n(Sequential Window acquisition of All THeoretical mass spectra) has become a\\ncornerstone for the worldwide proteomics community. In this approach, a\\nhigh-resolution quadrupole-ToF mass spectrometer acquires thousands of MS/MS\\ndata by selecting not just a single precursor at a time, but by allowing a\\nbroad m/z range to be fragmented. This acquisition window is then sequentially\\nmoved from the lowest to the highest mass selection range. This technique\\nenables the acquisition of thousands of high-resolution MS/MS spectra per\\nminute in a standard LC-MS run. In the subsequent data analysis phase, the\\ncorresponding dataset is searched in a triple quadrupole-like mode, thus not\\nconsidering the whole MS/MS scan spectrum, but by searching for several\\nprecursor to fragment transitions that identify and quantify the corresponding\\npeptide. This search is made possible with the use of an ion library,\\npreviously acquired in a classical data dependent, full-spectrum mode. The\\nSWATH protocol, combining the protein identification power of high-resolution\\nMS/MS spectra with the robustness and accuracy in analyte quantification of\\ntriple-quad targeted workflows, has become very popular in proteomics research.\\nThe major drawback lies in the ion library itself, which is normally demanding\\nand time-consuming to build. Conversely, through the realignment of\\nchromatographic retention times, an ion library of a given proteome can\\nrelatively easily be tailored upon any proteomics experiment done on the same\\nproteome. We are thus hereby sharing with the worldwide proteomics community\\nour newly acquired ion library of mouse adult hippocampal neural stem cells.\\nGiven the growing effort in neuroscience research involving proteomics\\nexperiments, we believe that this data might be of great help for the\\nneuroscience community.\\n',\n",
       " 'We study the connection between triangulations of a type $A$ root polytope\\nand the resonance arrangement, a hyperplane arrangement that shows up in a\\nsurprising number of contexts. Despite an elementary definition for the\\nresonance arrangement, the number of resonance chambers has only been computed\\nup to the $n=8$ dimensional case. We focus on data structures for labeling\\nchambers, such as sign vectors and sets of alternating trees, with an aim at\\nbetter understanding the structure of the resonance arrangement, and, in\\nparticular, enumerating its chambers. Along the way, we make connections with\\nsimilar (and similarly difficult) enumeration questions. With the root polytope\\nviewpoint, we relate resonance chambers to the chambers of polynomiality of the\\nKostant partition function. With the hyperplane viewpoint, we clarify the\\nconnections between resonance chambers and threshold functions. In particular,\\nwe show that the base-2 logarithm of the number of resonance chambers is\\nasymptotically $n^2$.\\n',\n",
       " 'This article studies nonparametric methods to estimate the co-integrated\\nvolatility for multi-dimensional Lévy processes with high frequency data. We\\nconstruct a spectral estimator for the co-integrated volatility and prove\\nminimax rates for an appropriate bounded nonparametric class of\\nsemimartingales. Given $ n $ observations of increments over intervals of\\nlength $1/n$, the rates of convergence are $1 / \\\\sqrt{n} $ if $ r \\\\leq 1 $ and\\n$ (n\\\\log n)^{(r-2)/2} $ if $ r>1 $, which are optimal in a minimax sense. We\\nbound the co-jump index activity from below with the harmonic mean. Finally, we\\nassess the efficiency of our estimator by comparing it with estimators in the\\nexisting literature.\\n',\n",
       " 'Synchrotron radiation from the interstellar medium (ISM) of our galaxy\\ndominates the sky brightness at low radio frequencies, and carries information\\nabout relativistic and thermal electron distributions across a range of\\nastrophysical environments. The polarization of the radiation, as modified by\\nFaraday rotation effects in the ISM, also contains extensive information about\\nthe magnetic field. Comprehensive all-sky broadband mapping of this radiation,\\nwhen combined with high frequency radio data, gamma ray data, cosmic ray (CR)\\nmeasurements and sophisticated modeling, can revolutionize our understanding of\\nthe ISM and the processes that influence its evolution.\\nCurrent widefield imagery of the galactic synchrotron emission is\\nheterogeneous in frequency coverage, sky coverage, angular resolution and\\ncalibration accuracy, limiting utility for ISM studies. A new generation of\\nall-digital low frequency array technologies is opening a path to matched\\nresolution, high fidelity polarimetric imaging across a fully sampled swath of\\nradio frequencies from a few tens to many hundreds of MHz, generating a\\ntransformational dataset for a broad range of scientific applications.\\n',\n",
       " \"Learning data representations that reflect the customers' creditworthiness\\ncan improve marketing campaigns, customer relationship management, data and\\nprocess management or the credit risk assessment in retail banks. In this\\nresearch, we adopt the Variational Autoencoder (VAE), which has the ability to\\nlearn latent representations that contain useful information. We show that it\\nis possible to steer the latent representations in the latent space of the VAE\\nusing the Weight of Evidence and forming a specific grouping of the data that\\nreflects the customers' creditworthiness. Our proposed method learns a latent\\nrepresentation of the data, which shows a well-defied clustering structure\\ncapturing the customers' creditworthiness. These clusters are well suited for\\nthe aforementioned banks' activities. Further, our methodology generalizes to\\nnew customers, captures high-dimensional and complex financial data, and scales\\nto large data sets.\\n\",\n",
       " 'We define a proportionally dense subgraph (PDS) as an induced subgraph of a\\ngraph with the property that each vertex in the PDS is adjacent to\\nproportionally as many vertices in the subgraph as in the graph. We prove that\\nthe problem of finding a PDS of maximum size is APX-hard on split graphs, and\\nNP-hard on bipartite graphs. We also show that deciding if a PDS is\\ninclusion-wise maximal is co-NP-complete on bipartite graphs. Nevertheless, we\\npresent a simple polynomial-time $(2-\\\\frac{2}{\\\\Delta+1})$-approximation\\nalgorithm for the problem, where $\\\\Delta$ is the maximum degree of the graph.\\nFinally, we prove that all Hamiltonian cubic graphs (except two) have a PDS of\\nthe maximum possible size which can be found in linear time if a Hamiltonian\\ncycle is given in input.\\n',\n",
       " 'In this paper, we introduce a new problem of manipulating a given video by\\ninserting other videos into it. Our main task is, given an object video and a\\nscene video, to insert the object video at a user-specified location in the\\nscene video so that the resulting video looks realistic. We aim to handle\\ndifferent object motions and complex backgrounds without expensive segmentation\\nannotations. As it is difficult to collect training pairs for this problem, we\\nsynthesize fake training pairs that can provide helpful supervisory signals\\nwhen training a neural network with unpaired real data. The proposed network\\narchitecture can take both real and fake pairs as input and perform both\\nsupervised and unsupervised training in an adversarial learning scheme. To\\nsynthesize a realistic video, the network renders each frame based on the\\ncurrent input and previous frames. Within this framework, we observe that\\ninjecting noise into previous frames while generating the current frame\\nstabilizes training. We conduct experiments on real-world videos in object\\ntracking and person re-identification benchmark datasets. Experimental results\\ndemonstrate that the proposed algorithm is able to synthesize long sequences of\\nrealistic videos with a given object video inserted.\\n',\n",
       " 'Bloom Filter is extensively deployed data structure in various applications\\nand research domain since its inception. Bloom Filter is able to reduce the\\nspace consumption in an order of magnitude. Thus, Bloom Filter is used to keep\\ninformation of a very large scale data. There are numerous variants of Bloom\\nFilters available, however, scalability is a serious dilemma of Bloom Filter\\nfor years. To solve this dilemma, there are also diverse variants of Bloom\\nFilter. However, the time complexity and space complexity become the key issue\\nagain. In this paper, we present a novel Bloom Filter to address the\\nscalability issue without compromising the performance, called scaleBF. scaleBF\\ndeploys many 3D Bloom Filter to filter the set of items. In this paper, we\\ntheoretically compare the contemporary Bloom Filter for scalability and scaleBF\\noutperforms in terms of time complexity.\\n',\n",
       " 'The current canonical approach to publishing cross-section data is to unfold\\nthe reconstructed distributions. Detector effects like efficiency and smearing\\nare undone mathematically, yielding distributions in true event properties.\\nThis is an ill-posed problem, as even small statistical variations in the\\nreconstructed data can lead to large changes in the unfolded spectra.\\nThis work presents an alternative or complementary approach: the\\nresponse-matrix-centred forward-folding approach. It offers a convenient way to\\nforward-fold model expectations in truth space to reconstructed quantities.\\nThese can then be compared to the data directly, similar to what is usually\\ndone with full detector simulations within the experimental collaborations. For\\nthis, the detector response (efficiency and smearing) is parametrised as a\\nmatrix. The effects of the detector on the measurement of a given model is\\nsimulated by simply multiplying the binned truth expectation values by this\\nresponse matrix.\\nSystematic uncertainties in the detector response are handled by providing a\\nset of matrices according to the prior distribution of the detector properties\\nand marginalising over them. Background events can be included in the\\nlikelihood calculation by giving background events their own bins in truth\\nspace.\\nTo facilitate a straight-forward use of response matrices, a new software\\nframework has been developed: the Response Matrix Utilities (ReMU). ReMU is a\\nPython package distributed via the Python Package Index. It only uses widely\\navailable, standard scientific Python libraries and does not depend on any\\ncustom experiment-specific software. It offers all methods needed to build\\nresponse matrices from Monte Carlo data sets, use the response matrix to\\nforward-fold truth-level model predictions, and compare the predictions to real\\ndata using Bayesian or frequentist statistical inference.\\n',\n",
       " 'Big Data is the most popular emerging trends that becomes a blessing for\\nhuman kinds and it is the necessity of day-to-day life. For example, Facebook.\\nEvery person involves with producing data either directly or indirectly. Thus,\\nBig Data is a high volume of data with exponential growth rate that consists of\\na variety of data. Big Data touches all fields, including Government sector, IT\\nindustry, Business, Economy, Engineering, Bioinformatics, and other basic\\nsciences. Thus, Big Data forms a data silo. Most of the data are duplicates and\\nunstructured. To deal with such kind of data silo, Bloom Filter is a precious\\nresource to filter out the duplicate data. Also, Bloom Filter is inevitable in\\na Big Data storage system to optimize the memory consumption. Undoubtedly,\\nBloom Filter uses a tiny amount of memory space to filter a very large data\\nsize and it stores information of a large set of data. However, functionality\\nof the Bloom Filter is limited to membership filter, but it can be adapted in\\nvarious applications. Besides, the Bloom Filter is deployed in diverse field,\\nand also used in the interdisciplinary research area. Bioinformatics, for\\ninstance. In this article, we expose the usefulness of Bloom Filter in Big Data\\nresearch.\\n',\n",
       " 'Second Harmonic Generation (SHG) of single-layer monochalcogenides, such as\\nGaSe and InSe, has been recently reported [2D Mater. 5 (2018) 025019; J. Am.\\nChem. Soc. 2015, 137, 79947997] to be extremely strong with respect to bulk and\\nmultilayer forms. To clarify the origin of this strong SHG signal, we perform\\nfirst-principles real-time simulations of linear and non-linear optical\\nproperties of these two-dimensional semiconducting materials. The simulations,\\nbased on ab-initio many-body theory, accurately treat the electron-hole\\ncorrelation and capture excitonic effects that are deemed important to\\ncorrectly predict the optical properties of such systems. We find indeed that,\\nas observed for other 2D systems, the SHG intensity is redistributed at\\nexcitonic resonances. The obtained theoretical SHG intensity is an order of\\nmagnitude smaller than that reported at the experimental level. This result is\\nin substantial agreement with previously published simulations which neglected\\nthe electron-hole correlation, demonstrating that many-body interactions are\\nnot at the origin of the strong SHG measured. We then show that the\\nexperimental data can be reconciled with the theoretical prediction when a\\nsingle layer model, rather than a bulk one, is used to extract the SHG\\ncoefficient from the experimental data.\\n',\n",
       " 'Geo-distributed systems often replicate data at multiple locations to achieve\\navailability and performance despite network partitions. These systems must\\naccept updates at any replica and propagate these updates asynchronously to\\nevery other replica. Conflict-Free Replicated Data Types (CRDTs) provide a\\nprincipled approach to the problem of ensuring that replicas are eventually\\nconsistent despite the asynchronous delivery of updates.\\nWe address the problem of specifying and verifying CRDTs, introducing a new\\ncorrectness criterion called Replication-Aware Linearizability. This criterion\\nis inspired by linearizability, the de-facto correctness criterion for\\n(shared-memory) concurrent data structures. We argue that this criterion is\\nboth simple to understand, and it fits most known implementations of CRDTs. We\\nprovide a proof methodology to show that a CRDT satisfies replication-aware\\nlinearizability which we apply on a wide range of implementations. Finally, we\\nshow that our criterion can be leveraged to reason modularly about the\\ncomposition of CRDTs.\\n',\n",
       " 'Using the Navarro-Frenk-White (NFW) dark matter density profile we\\nreconstruct an effective field theory model for gravity at large distances from\\na central object by demanding that the vacuum solution has the same\\ngravitational properties as the NFW density profile has in the context of\\nGeneral Relativity (GR). The dimensionally reduced reconstructed action for\\ngravity leads to a vacuum metric that includes a modified Rindler acceleration\\nterm in addition to the Schwarzschild and cosmological constant terms. The new\\nterm is free from infrared curvature singularities and leads to a much better\\nfit of observed galaxy velocity rotation curves than the corresponding simple\\nRindler term of the Grumiller metric, at the expense of one additional\\nparameter. When the new parameter is set to zero the new metric term reduces to\\na Rindler constant acceleration term. We use galactic velocity rotation data to\\nfind the best fit values of the parameters of the reconstructed geometric\\npotential and discuss possible cosmological implications.\\n',\n",
       " 'A central problem in hyperspectral image classification is obtaining high\\nclassification accuracy when using a limited amount of labelled data. In this\\npaper we present a novel graph-based framework, which aims to tackle this\\nproblem in the presence of large scale data input. Our approach utilises a\\nnovel superpixel method, specifically designed for hyperspectral data, to\\ndefine meaningful local regions in an image, which with high probability share\\nthe same classification label. We then extract spectral and spatial features\\nfrom these regions and use these to produce a contracted weighted\\ngraph-representation, where each node represents a region rather than a pixel.\\nOur graph is then fed into a graph-based semi-supervised classifier which gives\\nthe final classification. We show that using superpixels in a graph\\nrepresentation is an effective tool for speeding up graphical classifiers\\napplied to hyperspectral images. We demonstrate through exhaustive quantitative\\nand qualitative results that our proposed method produces accurate\\nclassifications when an incredibly small amount of labelled data is used. We\\nshow that our approach mitigates the major drawbacks of existing approaches,\\nresulting in our approach outperforming several comparative state-of-the-art\\ntechniques.\\n',\n",
       " 'Recent radio surveys have discovered a large number of low luminosity core\\ndominated radio galaxies that are much more abundant than those at higher\\nluminosities. These objects will be too faint in \\\\grays to be detected\\nindividually by {\\\\it Fermi}. Nevertheless, they may contribute significantly to\\nthe unresolved extragalactic \\\\gray background. We consider here the possible\\ncontribution of these core dominated radio galaxies to the diffuse\\nextragalactic \\\\gray background. Using published data available for all 45 of\\nthe radiogalaxies listed as detected counterparts in the {\\\\it Fermi} FL8Y\\nsource list update to the 3FGL catalog, we have searched for radio maps which\\ncan resolve the core flux from the total source flux. Using high resolution\\nradio maps we were able to obtain core fluxes for virtually every source. We\\nthen derived a relation between core radio flux and \\\\gray flux that we\\nextrapolated to sources with low radio luminosities that are known to be highly\\ncore dominated. We then employed a very recent determination of the luminosity\\nfunction for core dominated radio galaxies in order to obtain the contribution\\nof all possible \\\\gray emitting radio galaxies to the unresolved extragalactic\\n\\\\gray background. We find this contribution to be a possibly non-negligible,\\n4\\\\% - 18\\\\% of the background.\\n',\n",
       " 'For high contrast imaging systems, the time delay is one of the major\\nlimiting factors for the performance of the extreme adaptive optics (AO)\\nsub-system and, in turn, the final contrast. The time delay is due to the\\nfinite time needed to measure the incoming disturbance and then apply the\\ncorrection. By predicting the behavior of the atmospheric disturbance over the\\ntime delay we can in principle achieve a better AO performance. Atmospheric\\nturbulence parameters which determine the wavefront phase fluctuations have\\ntime-varying behavior. We present a stochastic model for wind speed and model\\ntime-variant atmospheric turbulence effects using varying wind speed. We test a\\nlow-order, data-driven predictor, the linear minimum mean square error\\npredictor, for a near-infrared AO system under varying conditions. Our results\\nshow varying wind can have a significant impact on the performance of wavefront\\nprediction, preventing it from reaching optimal performance. The impact depends\\non the strength of the wind fluctuations with the greatest loss in expected\\nperformance being for high wind speeds.\\n',\n",
       " 'Developments in transcriptomics techniques have caused a large demand in\\ntailored computational methods for modelling gene expression dynamics from\\nexperimental data. Recently, so-called single-cell experiments have\\nrevolutionised genetic studies. These experiments yield gene expression data in\\nsingle cell resolution for a large number of cells at a time. However, the\\ncells are destroyed in the measurement process, and so the data consist of\\nsnapshots of an ensemble evolving over time, instead of time series. The\\nproblem studied in this article is how such data can be used in modelling gene\\nregulatory dynamics. Two different paradigms are studied for linear system\\nidentification. The first is based on tracking the evolution of the\\ndistribution of cells over time. The second is based on the so-called\\npseudotime concept, identifying a common trajectory through the state space,\\nalong which cells propagate with different rates. Therefore, at any given time,\\nthe population contains cells in different stages of the trajectory. Resulting\\nmethods are compared in numerical experiments.\\n',\n",
       " 'The use of spatial information with multiple microphones can improve\\nfar-field automatic speech recognition (ASR) accuracy. However, conventional\\nmicrophone array techniques degrade speech enhancement performance when there\\nis an array geometry mismatch between design and test conditions. Moreover,\\nsuch speech enhancement techniques do not always yield ASR accuracy improvement\\ndue to the difference between speech enhancement and ASR optimization\\nobjectives. In this work, we propose to unify an acoustic model framework by\\noptimizing spatial filtering and long short-term memory (LSTM) layers from\\nmulti-channel (MC) input. Our acoustic model subsumes beamformers with multiple\\ntypes of array geometry. In contrast to deep clustering methods that treat a\\nneural network as a black box tool, the network encoding the spatial filters\\ncan process streaming audio data in real time without the accumulation of\\ntarget signal statistics. We demonstrate the effectiveness of such MC neural\\nnetworks through ASR experiments on the real-world far-field data. We show that\\nour two-channel acoustic model can on average reduce word error rates (WERs)\\nby~13.4 and~12.7% compared to a single channel ASR system with the log-mel\\nfilter bank energy (LFBE) feature under the matched and mismatched microphone\\nplacement conditions, respectively. Our result also shows that our two-channel\\nnetwork achieves a relative WER reduction of over~7.0% compared to conventional\\nbeamforming with seven microphones overall.\\n',\n",
       " \"Event-based cameras can measure intensity changes (called `{\\\\it events}')\\nwith microsecond accuracy under high-speed motion and challenging lighting\\nconditions. With the active pixel sensor (APS), the event camera allows\\nsimultaneous output of the intensity frames. However, the output images are\\ncaptured at a relatively low frame-rate and often suffer from motion blur. A\\nblurry image can be regarded as the integral of a sequence of latent images,\\nwhile the events indicate the changes between the latent images. Therefore, we\\nare able to model the blur-generation process by associating event data to a\\nlatent image. Based on the abundant event data and the low frame-rate easily\\nblurred images, we propose a simple and effective approach to reconstruct a\\nhigh-quality and high frame-rate shape video. Starting with a single blurry\\nframe and its event data, we propose the \\\\textbf{Event-based Double Integral\\n(EDI)} model. Then, we extend it to \\\\textbf{ multiple Event-based Double\\nIntegral (mEDI)} model to get more smooth and convincing results based on\\nmultiple images and their events. We also provide an efficient solver to\\nminimize the proposed energy model. By optimizing the energy model, we achieve\\nsignificant improvements in removing general blurs and reconstructing high\\ntemporal resolution video. The video generation is based on solving a simple\\nnon-convex optimization problem in a single scalar variable. Experimental\\nresults on both synthetic and real images demonstrate the superiority of our\\nmEDI model and optimization method in comparison to the state-of-the-art.\\n\",\n",
       " 'In machine learning the best performance on a certain task is achieved by\\nfully supervised methods when perfect ground truth labels are available.\\nHowever, labels are often noisy, especially in remote sensing where manually\\ncurated public datasets are rare. We study the multi-modal cadaster map\\nalignment problem for which available annotations are mis-aligned polygons,\\nresulting in noisy supervision. We subsequently set up a multiple-rounds\\ntraining scheme which corrects the ground truth annotations at each round to\\nbetter train the model at the next round. We show that it is possible to reduce\\nthe noise of the dataset by iteratively training a better alignment model to\\ncorrect the annotation alignment.\\n',\n",
       " 'Current burning issues in stellar physics, for both hot and cool stars,\\nconcern their magnetism. In hot stars, stable magnetic fields of fossil origin\\nimpact their stellar structure and circumstellar environment, with a likely\\nmajor role in stellar evolution. However, this role is complex and thus poorly\\nunderstood as of today. It needs to be quantified with high-resolution UV\\nspectropolarimetric measurements. In cool stars, UV spectropolarimetry would\\nprovide access to the structure and magnetic field of the very dynamic upper\\nstellar atmosphere, providing key data for new progress to be made on the role\\nof magnetic fields in heating the upper atmospheres, launching stellar winds,\\nand more generally in the interaction of cool stars with their environment\\n(circumstellar disk, planets) along their whole evolution.\\n',\n",
       " 'Global Positioning System (GPS) derived precipitable water vapor (PWV) is\\nextensively being used in atmospheric remote sensing for applications like\\nrainfall prediction. Many applications require PWV values with good resolution\\nand without any missing values. In this paper, we implement an exponential\\nsmoothing method to accurately predict the missing PWV values. The method shows\\ngood performance in terms of capturing the seasonal variability of PWV values.\\nWe report a root mean square error of 0.1~mm for a lead time of 15 minutes,\\nusing past data of 30 hours measured at 5-minute intervals.\\n',\n",
       " 'We present an $r$--band photometric monitoring of the two images A and B of\\nthe gravitationally lensed quasar SDSS J1442+4055 using the Liverpool Telescope\\n(LT). From the LT light curves between 2015 December and 2018 August, we derive\\nat once a time delay of 25.0 $\\\\pm$ 1.5 days (1$\\\\sigma$ confidence interval; A\\nis leading) and microlensing magnification gradients below 10$^{-4}$ mag\\nday$^{-1}$. The delay interval is not expected to be affected by an appreciable\\nmicrolensing--induced bias, so it can be used to estimate cosmological\\nparameters. This paper also focuses on new Gran Telescopio Canarias (GTC) and\\nLT spectroscopic observations of the lens system. We determine the redshift of\\ntwo bright galaxies around the doubly imaged quasar using LT spectroscopy,\\nwhile GTC data lead to low--noise individual spectra of A, B, and the main\\nlensing galaxy G1. The G1 spectral shape is accurately matched to an\\nearly--type galaxy template at $z$ = 0.284, and it has potential for further\\nrelevant studies. Additionally, the quasar spectra show absorption by\\nmetal--rich gas at $z \\\\sim$ 2. This dusty absorber is responsible for an\\nextinction bump at a rest--frame wavelength of 2209 $\\\\pm$ 2 \\\\AA, which has\\nstrengths of $\\\\sim$ 0.47 and 0.76 mag $\\\\mu$m$^{-1}$ for A and B, respectively.\\nIn such intervening system, the dust--to--gas ratio, gas--phase metallicity\\nindicator [Zn/H], and dust depletion level [Fe/Zn] are relatively high.\\n',\n",
       " 'In this work, we derive a closed solution of the Shr$ \\\\ddot{o} $dinger\\nequation for Bohr Hamiltonien within the minimal length formalism. This\\nformalism is inspired by Heisenberg algebra and a generlized uncertainty\\nprinciple (GUP), applied to the geometrical collective Bohr- Mottelson model\\n(BMM) of nuclei by means of deformed canonical commutation relation and the\\nPauli-Podolsky prescription. The problem is solved by means conjointly of\\nasymptotic iteration method (AIM) and a quantum perturbation method (QPM) for\\ntransitional nuclei near the critical point symmetry Z(4) corresponding to\\nphase transition from prolate to $\\\\gamma$-rigid triaxial shape. A scaled\\nDavidson potentiel is used as a restoring potential in order to get physical\\nminimum. The agreement between the obtained theoretical results and the\\nexperimental data is very satisfactory.\\n',\n",
       " 'The R package colorspace provides a flexible toolbox for selecting individual\\ncolors or color palettes, manipulating these colors, and employing them in\\nstatistical graphics and data visualizations. In particular, the package\\nprovides a broad range of color palettes based on the HCL\\n(Hue-Chroma-Luminance) color space. The three HCL dimensions have been shown to\\nmatch those of the human visual system very well, thus facilitating intuitive\\nselection of color palettes through trajectories in this space. Using the HCL\\ncolor model general strategies for three types of palettes are implemented: (1)\\nQualitative for coding categorical information, i.e., where no particular\\nordering of categories is available. (2) Sequential for coding ordered/numeric\\ninformation, i.e., going from high to low (or vice versa). (3) Diverging for\\ncoding ordered/numeric information around a central neutral value, i.e., where\\ncolors diverge from neutral to two extremes. To aid selection and application\\nof these palettes the package also contains scales for use with ggplot2, shiny\\n(and tcltk) apps for interactive exploration, visualizations of palette\\nproperties, accompanying manipulation utilities (like desaturation and\\nlighten/darken), and emulation of color vision deficiencies.\\n',\n",
       " \"Existing strategies for determining the optimal treatment or monitoring\\nstrategy typically assume unlimited access to resources. However, when a health\\nsystem has resource constraints, such as limited funds, access to medication,\\nor monitoring capabilities, medical decisions must balance impacts on both\\nindividual and population health outcomes. That is, decisions should account\\nfor competition between individuals in resource usage. One simple solution is\\nto estimate the (counterfactual) resource usage under the possible\\ninterventions and choose the optimal strategy for which resource usage is\\nwithin acceptable limits. We propose a method to identify the optimal dynamic\\nintervention strategy that leads to the best expected health outcome accounting\\nfor a health system's resource constraints. We then apply this method to\\ndetermine the optimal dynamic monitoring strategy for people living with HIV\\nwhen resource limits on monitoring exist using observational data from the\\nHIV-CAUSAL Collaboration.\\n\",\n",
       " 'We present a computational framework for the simulation of blood flow with\\nfully resolved red blood cells (RBCs) using a modular approach that consists of\\na lattice Boltzmann solver for the blood plasma, a novel finite element based\\nsolver for the deformable bodies and an immersed boundary method for the\\nfluid-solid interaction. For the RBCs, we propose a nodal projective FEM\\n(npFEM) solver which has theoretical advantages over the more commonly used\\nmass-spring systems (mesoscopic modeling), such as an unconditional stability,\\nversatile material expressivity, and one set of parameters to fully describe\\nthe behavior of the body at any mesh resolution. At the same time, the method\\nis substantially faster than other FEM solvers proposed in this field, and has\\nan efficiency that is comparable to the one of mesoscopic models. At its core,\\nthe solver uses specially defined potential energies, and builds upon them a\\nfast iterative procedure based on quasi-Newton techniques. For a known\\nmaterial, our solver has only one free parameter that demands tuning, related\\nto the body viscoelasticity. In contrast, state-of-the-art solvers for\\ndeformable bodies have more free parameters, and the calibration of the models\\ndemands special assumptions regarding the mesh topology, which restrict their\\ngenerality and mesh independence. We propose as well a correction to the\\npotential energy proposed by Skalak et al. 1973 for the red blood cell\\nmembrane, which enhances the strain hardening behavior at higher deformations.\\nOur viscoelastic model for the red blood cell, while simple enough and\\napplicable to any kind of solver as a post-convergence step, can capture\\naccurately the characteristic recovery time and tank-treading frequencies. The\\nframework is validated using experimental data, and it proves to be scalable\\nfor multiple deformable bodies.\\n',\n",
       " 'Hadronic spectral densities are important quantities whose non-perturbative\\nknowledge allows for calculating phenomenologically relevant observables, such\\nas inclusive hadronic cross-sections and non-leptonic decay-rates. The\\nextraction of spectral densities from lattice correlators is a notoriously\\ndifficult problem because lattice simulations are performed in Euclidean time\\nand lattice data are unavoidably affected by statistical and systematic\\nuncertainties. In this paper we present a new method for extracting hadronic\\nspectral densities from lattice correlators. The method allows for choosing a\\nsmearing function at the beginning of the procedure and it provides results for\\nthe spectral densities smeared with this function together with reliable\\nestimates of the associated uncertainties. The same smearing function can be\\nused in the analysis of correlators obtained on different volumes, such that\\nthe infinite volume limit can be studied in a consistent way. While the method\\nis described by using the language of lattice simulations, in reality it is\\ncompletely general and can profitably be used to cope with inverse problems\\narising in different fields of research.\\n',\n",
       " 'The segmentation of a gaze trace into its constituent eye movements has been\\nactively researched since the early days of eye tracking. As we move towards\\nmore naturalistic viewing conditions, the segmentation becomes even more\\nchallenging and convoluted as more complex patterns emerge. The definitions and\\nthe well-established methods that were developed for monitor-based eye tracking\\nexperiments are often not directly applicable to unrestrained set-ups such as\\neye tracking in wearable contexts or with head-mounted displays. The main\\ncontributions of this work to the eye movement research for 360-degree content\\nare threefold: First, we collect, partially annotate, and make publicly\\navailable a new eye tracking data set, which consists of 13 participants\\nviewing 15 video clips that are recorded in 360-degree. Second, we propose a\\nnew two-stage pipeline for ground truth annotation of the traditional\\nfixations, saccades, smooth pursuits, as well as (optokinetic) nystagmus,\\nvestibulo-ocular reflex, and pursuit of moving objects performed exclusively\\nvia the movement of the head. A flexible user interface for this pipeline is\\nimplemented and made freely accessible for use or modification. Lastly, we\\ndevelop and test a simple proof-of-concept algorithm for automatic\\nclassification of all the eye movement types in our data set based on their\\noperational definitions that were used for manual annotation. The data set and\\nthe source code for both the annotation tool and the algorithm are publicly\\navailable at this https URL.\\n',\n",
       " \"We propose DeepHuman, a deep learning based framework for 3D human\\nreconstruction from a single RGB image. Since this problem is highly\\nintractable, we adopt a stage-wise, coarse-to-fine method consisting of three\\nsteps, namely body shape/pose estimation, surface reconstruction and frontal\\nsurface detail refinement. Once a body is estimated from the given image, our\\nmethod generates a dense semantic representation from it. The representations\\nnot only encodes body shape and pose but also bridges the 2D image plane and 3D\\nspace. An image-guided volume-to-volume translation CNN is introduced to\\nreconstruct the surface given the input image and the dense semantic\\nrepresentation. One key feature of our network is that it fuses different\\nscales of image features into the 3D space through volumetric feature\\ntransformation, which helps to recover details of the subject's surface\\ngeometry. The details on the frontal areas of the surface are further refined\\nthrough a normal map refinement network. The normal refinement network can be\\nconcatenated with the volume generation network using our proposed volumetric\\nnormal projection layer. We also contribute THuman, a 3D real-world human model\\ndataset containing approximately 7000 models. The whole network is trained\\nusing training data generated from the dataset. Overall, due to the specific\\ndesign of our network and the diversity in our dataset, our method enables 3D\\nhuman reconstruction given only a single image and outperforms state-of-the-art\\napproaches.\\n\",\n",
       " 'Data science can offer answers to a wide range of social science questions.\\nHere we turn attention to the portrayal of women in movies, an industry that\\nhas a significant influence on society, impacting such aspects of life as\\nself-esteem and career choice. To this end, we fused data from the online movie\\ndatabase IMDb with a dataset of movie dialogue subtitles to create the largest\\navailable corpus of movie social networks (16,303 networks). Analyzing this\\ndata, we investigated gender bias in on-screen female characters over the past\\ncentury.\\nWe find a trend of improvement in all aspects of women`s roles in movies,\\nincluding a constant rise in the centrality of female characters. There has\\nalso been an increase in the number of movies that pass the well-known Bechdel\\ntest, a popular---albeit flawed---measure of women in fiction. Here we propose\\na new and better alternative to this test for evaluating female roles in\\nmovies. Our study introduces fresh data, an open-code framework, and novel\\ntechniques that present new opportunities in the research and analysis of\\nmovies.\\n',\n",
       " 'With the tremendous growth in the number of scientific papers being\\npublished, searching for references while writing a scientific paper is a\\ntime-consuming process. A technique that could add a reference citation at the\\nappropriate place in a sentence will be beneficial. In this perspective,\\ncontext-aware citation recommendation has been researched upon for around two\\ndecades. Many researchers have utilized the text data called the context\\nsentence, which surrounds the citation tag, and the metadata of the target\\npaper to find the appropriate cited research. However, the lack of\\nwell-organized benchmarking datasets and no model that can attain high\\nperformance has made the research difficult.\\nIn this paper, we propose a deep learning based model and well-organized\\ndataset for context-aware paper citation recommendation. Our model comprises a\\ndocument encoder and a context encoder, which uses Graph Convolutional Networks\\n(GCN) layer and Bidirectional Encoder Representations from Transformers (BERT),\\nwhich is a pre-trained model of textual data. By modifying the related PeerRead\\ndataset, we propose a new dataset called FullTextPeerRead containing context\\nsentences to cited references and paper metadata. To the best of our knowledge,\\nThis dataset is the first well-organized dataset for context-aware paper\\nrecommendation. The results indicate that the proposed model with the proposed\\ndatasets can attain state-of-the-art performance and achieve a more than 28%\\nimprovement in mean average precision (MAP) and recall@k.\\n',\n",
       " \"Industry 4.0 and the Internet of Things are recent developments that have\\nlead to the creation of new kinds of manufacturing data. Linking this new kind\\nof sensor data to traditional business information is crucial for enterprises\\nto take advantage of the data's full potential. In this paper, we present a\\ndemo which allows experiencing this data integration, both vertically between\\ntechnical and business contexts and horizontally along the value chain. The\\ntool simulates a manufacturing company, continuously producing both business\\nand sensor data, and supports issuing ad-hoc queries that answer specific\\nquestions related to the business. In order to adapt to different environments,\\nusers can configure sensor characteristics to their needs.\\n\",\n",
       " 'In the scalar 1D case, conservation laws and Hamilton-Jacobi equations are\\ndeeply related. For both, we characterize those profiles that can be attained\\nas solutions at a given positive time corresponding to at least one initial\\ndatum. Then, for each of the two equations, we precisely identify all those\\ninitial data yielding a solution that coincide with a given profile at that\\npositive time. Various topological and geometrical properties of the set of\\nthese initial data are then proved. 2000 Mathematics Subject Classification:\\n35L65, 35F21, 93B30, 35R30.\\n',\n",
       " 'Affective Computing is a rapidly growing field spurred by advancements in\\nartificial intelligence, but often, held back by the inability to translate\\npsychological theories of emotion into tractable computational models. To\\naddress this, we propose a probabilistic programming approach to affective\\ncomputing, which models psychological-grounded theories as generative models of\\nemotion, and implements them as stochastic, executable computer programs. We\\nfirst review probabilistic approaches that integrate reasoning about emotions\\nwith reasoning about other latent mental states (e.g., beliefs, desires) in\\ncontext. Recently-developed probabilistic programming languages offer several\\nkey desidarata over previous approaches, such as: (i) flexibility in\\nrepresenting emotions and emotional processes; (ii) modularity and\\ncompositionality; (iii) integration with deep learning libraries that\\nfacilitate efficient inference and learning from large, naturalistic data; and\\n(iv) ease of adoption. Furthermore, using a probabilistic programming framework\\nallows a standardized platform for theory-building and experimentation:\\nCompeting theories (e.g., of appraisal or other emotional processes) can be\\neasily compared via modular substitution of code followed by model comparison.\\nTo jumpstart adoption, we illustrate our points with executable code that\\nresearchers can easily modify for their own models. We end with a discussion of\\napplications and future directions of the probabilistic programming approach.\\n',\n",
       " 'Recently, edge caching and multicasting arise as two promising technologies\\nto support high-data-rate and low-latency delivery in wireless communication\\nnetworks. In this paper, we design three transmission schemes aiming to\\nminimize the delivery latency for cache-enabled multigroup multicasting\\nnetworks. In particular, full caching bulk transmission scheme is first\\ndesigned as a performance benchmark for the ideal situation where the caching\\ncapability of each enhanced remote radio head (eRRH) is sufficient large to\\ncache all files. For the practical situation where the caching capability of\\neach eRRH is limited, we further design two transmission schemes, namely\\npartial caching bulk transmission (PCBT) and partial caching pipelined\\ntransmission (PCPT) schemes. In the PCBT scheme, eRRHs first fetch the uncached\\nrequested files from the baseband unit (BBU) and then all requested files are\\nsimultaneously transmitted to the users. In the PCPT scheme, eRRHs first\\ntransmit the cached requested files while fetching the uncached requested files\\nfrom the BBU. Then, the remaining cached requested files and fetched uncached\\nrequested files are simultaneously transmitted to the users. The design goal of\\nthe three transmission schemes is to minimize the delivery latency, subject to\\nsome practical constraints. Efficient algorithms are developed for the\\nlow-latency cloud-edge coordinated transmission strategies. Numerical results\\nare provided to evaluate the performance of the proposed transmission schemes\\nand show that the PCPT scheme outperforms the PCBT scheme in terms of the\\ndelivery latency criterion.\\n',\n",
       " 'With a hybrid MEG--MRI device that uses the same sensors for both modalities,\\nthe co-registration of MRI and MEG data can be replaced by an automatic\\ncalibration step. Based on the highly accurate signal model of ultra-low-field\\n(ULF) MRI, we introduce a calibration method that eliminates the error sources\\nof traditional co-registration. The signal model includes complex sensitivity\\nprofiles of the superconducting pickup coils. In ULF MRI, the profiles are\\nindependent of the sample and therefore well-defined. In the most basic form,\\nthe spatial information of the profiles, captured in parallel ULF-MR\\nacquisitions, is used to find the exact coordinate transformation required. We\\nassessed our calibration method by simulations assuming a helmet-shaped\\npickup-coil-array geometry. Using a carefully constructed objective function\\nand sufficient approximations, even with low-SNR images, sub-voxel and\\nsub-millimeter calibration accuracy was achieved. After the calibration,\\ndistortion-free MRI and high spatial accuracy for MEG source localization can\\nbe achieved. For an accurate sensor-array geometry, the co-registration and\\nassociated errors are eliminated, and the positional error can be reduced to a\\nnegligible level.\\n',\n",
       " 'Observations of bright and variable \"reflected\" X-ray emission from molecular\\nclouds located within inner hundred parsec of our Galaxy have demonstrated that\\nthe central supermassive black hole, Sgr A*, experienced short and powerful\\nflares in the past few hundred years. These flares offer a truly unique\\nopportunity to determine 3D location of the illuminated clouds (with ~10 pc\\naccuracy) and to reveal their internal structure (down to 0.1 pc scales). Short\\nduration of the flare(s), combined with X-rays high penetration power and\\ninsensitivity of the reflection signal to thermo- and chemo-dynamical state of\\nthe gas, ensures that the provided diagnostics of the density and velocity\\nfields is unbiased and almost free of the projection and opacity effects. Sharp\\nand sensitive snapshots of molecular gas accessible with aid of future X-ray\\nobservatories featuring large collecting area and high angular (arcsec-level)\\nand spectral (eV-level) resolution cryogenic bolometers will present invaluable\\ninformation on properties of the supersonic turbulence inside the illuminated\\nclouds, map their shear velocity field and allow cross-matching between X-ray\\ndata and velocity-resolved emission of various molecular species provided by\\nALMA and other ground-based facilities. This will highlight large and\\nsmall-scale dynamics of the dense gas and help uncovering specifics of the ISM\\nlifecycle and high-mass star formation under very extreme conditions of\\ngalactic centers. While the former is of particular importance for the SMBH\\nfeeding and triggering AGN feedback, the latter might be an excellent test case\\nfor star formation taking place in high-redshift galaxies.\\n',\n",
       " 'The paper revisits the performance evaluation of caching in a Named Data\\nNetworking (NDN) router where the content store (CS) is supplemented by a\\npending interest table (PIT). The PIT aggregates requests for a given content\\nthat arrive within the download delay and thus brings an additional reduction\\nin upstream bandwidth usage beyond that due to CS hits. We extend prior work on\\ncaching with non-zero download delay (non-ZDD) by proposing a novel\\nmathematical framework that is more easily applicable to general traffic models\\nand by considering alternative cache insertion policies. Specifically we\\nevaluate the use of an LRU filter to improve CS hit rate performance in this\\nnon-ZDD context. We also consider the impact of time locality in demand due to\\nfinite content lifetimes. The models are used to quantify the impact of the PIT\\non upstream bandwidth reduction, demonstrating notably that this is significant\\nonly for relatively small content catalogues or high average request rate per\\ncontent. We further explore how the effectiveness of the filter with finite\\ncontent lifetimes depends on catalogue size and traffic intensity.\\n',\n",
       " 'A search for the decays $B^+ \\\\rightarrow h_c K^+$ and $B^0 \\\\rightarrow h_c\\nK_S^0$ is performed. Evidence for the decay $B^+ \\\\rightarrow h_c K^+$ is found;\\nits significance is $4.8\\\\sigma$. No evidence is found for $B^0 \\\\rightarrow h_c\\nK_S^0$. The branching fraction for $B^+ \\\\rightarrow h_c K^+$ is measured to be\\n$(3.7^{+1.0}_{-0.9}{}^{+0.8}_{-0.8}) \\\\times 10^{-5}$; the upper limit for the\\n$B^0 \\\\rightarrow h_c K_S^0$ branching fraction is $1.4 \\\\times 10^{-5}$ at\\n$90\\\\%$ C.L. In addition, a study of the $p \\\\bar{p} \\\\pi^+ \\\\pi^-$ invariant mass\\ndistribution in the channel $B^+ \\\\to (p \\\\bar{p} \\\\pi^+ \\\\pi^-) K^+$ results in\\nthe first observation of the decay $\\\\eta_c(2S) \\\\to p \\\\bar{p} \\\\pi^+ \\\\pi^-$ with\\n$12.1\\\\sigma$ significance. The analysis is based on the 711 $\\\\mathrm{fb}^{-1}$\\ndata sample collected by the Belle detector at the asymmetric-energy $e^+ e^-$\\ncollider KEKB at the $\\\\Upsilon(4S)$ resonance.\\n',\n",
       " 'A $k$-junta function is a function which depends on only $k$ coordinates of\\nthe input. For relatively small $k$ w.r.t. the input size $n$, learning\\n$k$-junta functions is one of fundamental problems both theoretically and\\npractically in machine learning. For the last two decades, much effort has been\\nmade to design efficient learning algorithms for Boolean junta functions, and\\nsome novel techniques have been developed. However, in real world,\\nmulti-labeled data seem to be obtained in much more often than binary-labeled\\none. Thus, it is a natural question whether these techniques can be applied to\\nmore general cases about the alphabet size.\\nIn this paper, we expand the Fourier detection techniques for the binary\\nalphabet to any finite field $\\\\mathbb{F}_q$, and give, roughly speaking, an\\n$O(n^{0.8k})$-time learning algorithm for $k$-juntas over $\\\\mathbb{F}_q$. Note\\nthat our algorithm is the first non-trivial (i.e., non-brute force) algorithm\\nfor such a class even in the case where $q=3$ and we give an affirmative answer\\nto the question posed in [MOS04].\\nOur algorithm consists of two reductions: (1) from learning juntas to LDME\\nwhich is a variant of the learning with errors (LWE) problems introduced by\\n[Reg05], and (2) from LDME to the light bulb problem (LBP) introduced by\\n[Val88]. Since the reduced problem (i.e., LBP) is a kind of binary problem\\nregardless of the alphabet size of the original problem (i.e., learning\\njuntas), we can directly apply the techniques for the binary case in the\\nprevious work such as in [Val15, KKK18].\\n',\n",
       " 'Collective emotion has been traditionally evaluated by questionnaire survey\\non a limited number of people. Recently, big data of written texts on the\\nInternet has been available for analyzing collective emotion for very large\\nscales. Although short-term reflection between collective emotion and real\\nsocial phenomena has been widely studied, long-term dynamics of collective\\nemotion has not been studied so far due to the lack of long persistent data\\nsets. In this study, we extracted collective emotion over a 10-year period from\\n3.6 billion Japanese blog articles. Firstly, we find that collective emotion\\nshows clear periodic cycles, i.e., weekly and seasonal behaviors, accompanied\\nwith pulses caused by natural disasters. For example, April is represented by\\nhigh Tension, probably due to starting school in Japan. We also identified\\nlong-term memory in the collective emotion that is characterized by the\\npower-law decay of the autocorrelation function over several months.\\n',\n",
       " 'Because of the open nature of the Wireless Sensor Networks (WSN), the Denial\\nof the Service (DoS) becomes one of the most serious threats to the stability\\nof the resourceconstrained sensor nodes. In this paper, we develop AccFlow\\nwhich is an incrementally deployable Software-Defined Networking based protocol\\nthat is able to serve as a countermeasure against the low-rate TCP DoS attack.\\nThe main idea of AccFlow is to make the attacking flows accountable for the\\ncongestion by dropping their packets according to their loss rates. The larger\\ntheir loss rates, the more aggressively AccFlow drops their packets. Through\\nextensive simulations, we demonstrate that AccFlow can effectively defend\\nagainst the low-rate TCP DoS attack even if attackers vary their strategies by\\nattacking at different scales and data rates. Furthermore, while AccFlow is\\ndesigned to solve the low-rate TCP DoS attack, we demonstrate that AccFlow can\\nalso effectively defend against general DoS attacks which do not rely on the\\nTCP retransmission timeout mechanism but cause denial of service to legitimate\\nusers by consistently exhausting the network resources. Finally, we consider\\nthe scalability of AccFlow and its deployment in real networks.\\n',\n",
       " 'The Commensal Radio Astronomy Five-hundred-meter Aperture Spherical radio\\nTelescope (FAST) Survey (CRAFTS) utilizes the novel drift-scan commensal survey\\nmode of FAST and can generate billions of pulsar candidate signals. The human\\nexperts are not likely to thoroughly examine these signals, and various machine\\nsorting methods are used to aid the classification of the FAST candidates. In\\nthis study, we propose a new ensemble classification system for pulsar\\ncandidates. This system denotes the further development of the pulsar\\nimage-based classification system (PICS), which was used in the Arecibo\\nTelescope pulsar survey, and has been retrained and customized for the FAST\\ndrift-scan survey. In this study, we designed a residual network model\\ncomprising 15 layers to replace the convolutional neural networks (CNNs) in\\nPICS. The results of this study demonstrate that the new model can sort >96% of\\nreal pulsars to belong the top 1% of all candidates and classify >1.6 million\\ncandidates per day using a dual--GPU and 24--core computer. This increased\\nspeed and efficiency can help to facilitate real-time or quasi-real-time\\nprocessing of the pulsar-search data stream obtained from CRAFTS. In addition,\\nwe have published the labeled FAST data used in this study online, which can\\naid in the development of new deep learning techniques for performing pulsar\\nsearches.\\n',\n",
       " 'This paper explores the theoretical limits of using discrete abstractions for\\nnonlinear control synthesis. More specifically, we consider the problem of\\ndeciding continuous-time control with temporal logic specifications. We prove\\nthat sampled-data control of nonlinear systems with temporal logic\\nspecifications is robustly decidable in the sense that, given a continuous-time\\nnonlinear control system and a temporal logic formula, one can algorithmically\\ndecide whether there exists a robust sampled-data control strategy to realize\\nthis specification when the right-hand side of the system is slightly perturbed\\nby a small disturbance. If the answer is positive, one can then construct a\\n(potentially less) robust sampled-data control strategy that realizes the same\\nspecification. The result is proved by constructing a robustly complete\\nabstraction of the original continuous-time control system using sufficiently\\nsmall discretization parameters. We illustrate the result with a nonlinear\\ncontrol example.\\n',\n",
       " 'We give a deterministic, nearly logarithmic-space algorithm that given an\\nundirected graph $G$, a positive integer $r$, and a set $S$ of vertices,\\napproximates the conductance of $S$ in the $r$-step random walk on $G$ to\\nwithin a factor of $1+\\\\epsilon$, where $\\\\epsilon>0$ is an arbitrarily small\\nconstant. More generally, our algorithm computes an $\\\\epsilon$-spectral\\napproximation to the normalized Laplacian of the $r$-step walk.\\nOur algorithm combines the derandomized square graph operation (Rozenman and\\nVadhan, 2005), which we recently used for solving Laplacian systems in nearly\\nlogarithmic space (Murtagh, Reingold, Sidford, and Vadhan, 2017), with ideas\\nfrom (Cheng, Cheng, Liu, Peng, and Teng, 2015), which gave an algorithm that is\\ntime-efficient (while ours is space-efficient) and randomized (while ours is\\ndeterministic) for the case of even $r$ (while ours works for all $r$). Along\\nthe way, we provide some new results that generalize technical machinery and\\nyield improvements over previous work. First, we obtain a nearly linear-time\\nrandomized algorithm for computing a spectral approximation to the normalized\\nLaplacian for odd $r$. Second, we define and analyze a generalization of the\\nderandomized square for irregular graphs and for sparsifying the product of two\\ndistinct graphs. As part of this generalization, we also give a strongly\\nexplicit construction of expander graphs of every size.\\n',\n",
       " 'Formality style transformation is the task of modifying the formality of a\\ngiven sentence without changing its content. Its challenge is the lack of\\nlarge-scale sentence-aligned parallel data. In this paper, we propose an\\nomnivorous model that takes parallel data and formality-classified data jointly\\nto alleviate the data sparsity issue. We empirically demonstrate the\\neffectiveness of our approach by achieving the state-of-art performance on a\\nrecently proposed benchmark dataset of formality transfer. Furthermore, our\\nmodel can be readily adapted to other unsupervised text style transfer tasks\\nlike unsupervised sentiment transfer and achieve competitive results on three\\nwidely recognized benchmarks.\\n',\n",
       " 'Subset selection for matrices is the task of extracting a column sub-matrix\\nfrom a given matrix $B\\\\in\\\\mathbb{R}^{n\\\\times m}$ with $m>n$ such that the\\npseudoinverse of the sampled matrix has as small Frobenius or spectral norm as\\npossible. In this paper, we consider the more general problem of subset\\nselection for matrices that allows a block is fixed at the beginning. Under\\nthis setting, we provide a deterministic method for selecting a column\\nsub-matrix from $B$. We also present a bound for both the Frobenius and the\\nspectral matrix norms of the pseudoinverse of the sampled matrix with showing\\nthat the bound is asymptotically optimal. The main technology for proving this\\nresult is the interlacing families of polynomials which is developed by Marcus,\\nSpielman and Srivastava. This idea also results in a deterministic greedy\\nselection algorithm that produces the sub-matrix promised by our result.\\n',\n",
       " 'The accuracy and robustness of image classification with supervised deep\\nlearning are dependent on the availability of large-scale, annotated training\\ndata. However, there is a paucity of annotated data available due to the\\ncomplexity of manual annotation. To overcome this problem, a popular approach\\nis to use transferable knowledge across different domains by: 1) using a\\ngeneric feature extractor that has been pre-trained on large-scale general\\nimages (i.e., transfer-learned) but which not suited to capture characteristics\\nfrom medical images; or 2) fine-tuning generic knowledge with a relatively\\nsmaller number of annotated images. Our aim is to reduce the reliance on\\nannotated training data by using a new hierarchical unsupervised feature\\nextractor with a convolutional auto-encoder placed atop of a pre-trained\\nconvolutional neural network. Our approach constrains the rich and generic\\nimage features from the pre-trained domain to a sophisticated representation of\\nthe local image characteristics from the unannotated medical image domain. Our\\napproach has a higher classification accuracy than transfer-learned approaches\\nand is competitive with state-of-the-art supervised fine-tuned methods.\\n',\n",
       " 'Constrained-energy underwater acoustic nodes are typically connected via a\\nmulti-hop underwater acoustic network (MHUAN) to cover a broad marine region.\\nRecently, protocols for efficiently connecting such nodes have received\\nconsiderable attention. In this paper, we show that the time reversal (TR)\\nprocess plays an important role in the medium access control (MAC) because of\\nits physical capability to exploit the multi-path energy from the richly\\nscattering underwater environment, as well as to focus the signal energy in\\nboth spatial and temporal domains. In MHUANs, with severe multi-path\\npropagation at the physical layer, the active TR process spatially focuses the\\nsignals to the location of the intended receiver; this significantly diminishes\\nthe interference among parallel links. We propose an active TR-based MAC\\nprotocol for MHUANs, with the aim of minimizing collision and maximizing\\nchannel utilization simultaneously. Furthermore, by considering the impact of\\nthe cross-correlation between different links on the TR-based medium access, we\\nderive the threshold of the link cross-correlation to resolve collision caused\\nby the high cross-correlation between realistic links. We perform simulations\\nusing the OPNET and BELLHOP environments, and show that the proposed TR-based\\nMAC results in significantly improved throughput, decreased delay, and reduced\\ndata drop ratio in MHUANs.\\n',\n",
       " 'Discrepancy between training and testing domains is a fundamental problem in\\nthe generalization of machine learning techniques. Recently, several approaches\\nhave been proposed to learn domain invariant feature representations through\\nadversarial deep learning. However, label shift, where the percentage of data\\nin each class is different between domains, has received less attention. Label\\nshift naturally arises in many contexts, especially in behavioral studies where\\nthe behaviors are freely chosen. In this work, we propose a method called\\nDomain Adversarial nets for Target Shift (DATS) to address label shift while\\nlearning a domain invariant representation. This is accomplished by using\\ndistribution matching to estimate label proportions in a blind test set. We\\nextend this framework to handle multiple domains by developing a scheme to\\nupweight source domains most similar to the target domain. Empirical results\\nshow that this framework performs well under large label shift in synthetic and\\nreal experiments, demonstrating the practical importance.\\n',\n",
       " 'We consider the no-flux initial-boundary value problem for the\\ncross-diffusive evolution system \\\\begin{eqnarray*}\\n\\\\left\\\\{ \\\\begin{array}{ll}\\nu_t = u_{xx} - \\\\chi \\\\big(\\\\frac{u}{v} \\\\partial_x u \\\\big)_x - uv +B_1(x,t),\\n\\\\qquad & x\\\\in \\\\Omega, \\\\ t>0, \\\\\\\\[1mm]\\nv_t = v_{xx} +uv - v + B_2(x,t),\\n\\\\qquad & x\\\\in \\\\Omega, \\\\ t>0,\\n\\\\end{array} \\\\right. \\\\end{eqnarray*}\\nwhich was introduced by Short et al. in [Short2008] with $\\\\chi=2$ to describe\\nthe dynamics of urban crime\\nIn bounded intervals $\\\\Omega\\\\subset\\\\mathbb{R}$ and with prescribed suitably\\nregular nonnegative\\nfunctions $B_1$ and $B_2$, we first prove the existence of global classical\\nsolutions for any choice of $\\\\chi>0$ and all reasonably\\nregular nonnegative initial data. We next address the issue of determining\\nthe qualitative behavior of solutions under appropriate assumptions\\non the asymptotic properties of $B_1$ and $B_2$. Indeed, for arbitrary\\n$\\\\chi>0$ we obtain boundedness of the solutions given strict positivity of the\\naverage of $B_2$\\nover the domain; moreover, it is seen that imposing a mild decay assumption\\non $B_1$ implies that $u$ must\\ndecay to zero in the long-term limit.\\nOur final result, valid for all\\n$\\\\chi\\\\in\\\\left(0,\\\\frac{\\\\sqrt{6\\\\sqrt{3}+9}}{2}\\\\right),$ which contains\\nthe relevant value $\\\\chi=2$, states that under the above decay assumption on\\n$B_1$, if furthermore $B_2$ appropriately stabilizes to a\\nnontrivial function $B_{2,\\\\infty}$, then $(u,v)$ approaches the limit\\n$(0,v_\\\\infty)$, where $v_\\\\infty$\\ndenotes the solution of \\\\begin{eqnarray*}\\n\\\\left\\\\{ \\\\begin{array}{l}\\n-\\\\partial_{xx}v_\\\\infty + v_\\\\infty = B_{2,\\\\infty},\\n\\\\qquad x\\\\in \\\\Omega, \\\\\\\\[1mm]\\n\\\\partial_x v_{\\\\infty}=0,\\n\\\\qquad x\\\\in\\\\partial\\\\Omega.\\n\\\\end{array} \\\\right. \\\\end{eqnarray*}\\n',\n",
       " 'Adopting the parabolic-hyperbolic formulation of the constraint equations\\nintroduced by Rácz, we present a scheme to construct multiple black hole\\ninitial data sets without spin. We analyse the asymptotics by a combination of\\nanalytical and numerical techniques. As in earlier work we find that the\\nresulting initial data sets are, in general, not asymptotically flat. We\\naddress this issue by introducing an iterative scheme in order to approximate\\nasymptotic flatness.\\n',\n",
       " 'To assist with the commissioning (Jiang et al. 2019) of the\\nFive-hundred-meter Aperture Spherical radio Telescope (FAST), we performed a\\npulsar search, with the primary goal of developing and testing the pulsar data\\nacquisition and processing pipelines. We tested and used three pipelines, two\\n(P1 and P2 hereafter) searched for the periodic signature of pulsars whereas\\nthe other one was used to search for bright single pulses (P3 hereafter). A\\npulsar candidate was discovered in the observation on the 22nd August, 2017,\\nand later confirmed by the Parkes radio telescope on the 10th September, 2017.\\nThis pulsar, named PSR J1900-0134, was the first pulsar discovered by FAST. The\\npulsar has a pulse period of 1.8 s and a dispersion measure (DM) of\\n188\\\\,pc\\\\,cm$^{-3}$.\\n',\n",
       " 'We report the combined results of molecular dynamics simulations and\\ntheoretical calculations concerning various dynamical arrest transitions in a\\nmodel system representing a dipolar fluid, namely, N (softcore) rigid spheres\\ninteracting through a truncated dipole-dipole potential. By exploring different\\nregimes of concentration and temperature, we find three distinct scenarios for\\nthe slowing down of the dynamics of the translational and orientational degrees\\nof freedom: At low ({$\\\\eta$} = 0.2) and intermediate (${\\\\eta}$ = 0.4) volume\\nfractions, both dynamics are strongly coupled and become simultaneously\\narrested upon cooling. At high concentrations ({$\\\\eta$} $\\\\lt$ 0.6), the\\ntranslational dynamics shows the features of an ordinary glass transition,\\neither by compressing or cooling down the system, but with the orientations\\nremaining ergodic, thus indicating the existence of partially arrested states.\\nIn this density regime, but at lower temperatures, the relaxation of the\\norientational dynamics also freezes. The physical scenario provided by the\\nsimulations is discussed and compared against results obtained with the\\nself-consistent generalized Langevin equation theory, and both provide a\\nconsistent description of the dynamical arrest transitions in the system. Our\\nresults are summarized in an arrested states diagram which qualitatively\\norganizes the simulation data and provides a generic picture of the glass\\ntransitions of a dipolar fluid.\\n',\n",
       " \"A 2000-2017 set of long-period comets with high-quality orbits of perihelion\\ndistance <1 AU is used to show that the objects that perish shortly before\\nperihelion are nearly exclusively the Oort Cloud comets, especially those with\\nperihelia within 0.6 AU of the Sun, intrinsically fainter, and dust poor. Their\\npropensity for disintegration is much higher than predicted by Bortle's\\nperihelion survival rule, prompting the author to propose a new synoptic index\\nto be tested in future prognostication efforts. By their susceptibility to\\ndemise near the Sun, the nuclei of Oort Cloud comets differ dramatically from\\nthe nuclei of other long-period comets that almost always survive. In this\\nscenario, `Oumuamua -- discovered after perihelion -- is in all probability a\\nmajor piece of debris of an interstellar comet that was bound to perish near\\nperihelion if it was similar to, though much fainter than, the known Oort Cloud\\ncomets. The nondetection of `Oumuamua by the Spitzer Space Telescope is\\ncompatible with optical data for pancake shape, but not for cigar shape, with\\nthe maximum dimension not exceeding 160 m (at an 0.1 albedo). Although the\\nsolar radiation pressure induced nongravitational acceleration requires very\\nhigh porosity, `Oumuamua's estimated mass is orders of magnitude greater than\\nfor a cloud of unbound submicron-sized dust grains of equal cross section. The\\nacceleration could have displaced `Oumuamua by 250,000 km in 50 days,\\nscattering other potential debris over a large volume of space.\\n\",\n",
       " 'The general condition of the ocean surface at a certain location in space and\\ntime is described by the sea state. Knowing the distribution of the sea state\\nis, for example, important when estimating the wear and risks associated with a\\nplanned journey of a ship. One important characteristic of the sea state is the\\nsignificant wave height.\\nWe propose a spatial model for the logarithm of significant wave height based\\non a continuously indexed Gaussian random field defined as a solution to a\\nstochastic partial differential equation (SPDE). The SPDE is obtained by\\ncombining the SPDE representation of a stationary Gaussian Matérn field with\\nthe deformation approach by sampson and Guttorp (1992). The resulting model can\\ncapture both non-stationarity and anisotropy, has beneficial computational\\nproperties, and easily interpretable parameters. We also show that the\\nintroduction of non-stationarity through the deformation approach allow us to\\nderive theoretical bounds for exceedance probabilities of the field. Such\\nbounds are of importance when modelling extreme loads on ships.\\nThe parameters of the model are estimated on data of the north Atlantic taken\\nfrom the ERA-Interim data set. The fitted model is used to compute wave height\\nexceedance probabilities and the distribution of accumulated fatigue damage for\\nships traveling a popular shipping route. The computed distributions of fatigue\\ndamage and exceedence probability is shown to agree well with data.\\n',\n",
       " 'In this article I describe a research agenda for securing machine learning\\nmodels against adversarial inputs at test time. This article does not present\\nresults but instead shares some of my thoughts about where I think that the\\nfield needs to go. Modern machine learning works very well on I.I.D. data: data\\nfor which each example is drawn {\\\\em independently} and for which the\\ndistribution generating each example is {\\\\em identical}. When these assumptions\\nare relaxed, modern machine learning can perform very poorly. When machine\\nlearning is used in contexts where security is a concern, it is desirable to\\ndesign models that perform well even when the input is designed by a malicious\\nadversary. So far most research in this direction has focused on an adversary\\nwho violates the {\\\\em identical} assumption, and imposes some kind of\\nrestricted worst-case distribution shift. I argue that machine learning\\nsecurity researchers should also address the problem of relaxing the {\\\\em\\nindependence} assumption and that current strategies designed for robustness to\\ndistribution shift will not do so. I recommend {\\\\em dynamic models} that change\\neach time they are run as a potential solution path to this problem, and show\\nan example of a simple attack using correlated data that can be mitigated by a\\nsimple dynamic defense. This is not intended as a real-world security measure,\\nbut as a recommendation to explore this research direction and develop more\\nrealistic defenses.\\n',\n",
       " 'For a string $S$, a palindromic substring $S[i..j]$ is said to be a shortest\\nunique palindromic substring (SUPS) for an interval $[s, t]$ in $S$, if\\n$S[i..j]$ occurs exactly once in $S$, the interval $[i, j]$ contains $[s, t]$,\\nand every palindromic substring containing $[s, t]$ which is shorter than\\n$S[i..j]$ occurs at least twice in $S$. In this paper, we study the problem of\\nanswering $\\\\mathit{SUPS}$ queries on run-length encoded strings. We show how to\\npreprocess a given run-length encoded string $RLE_{S}$ of size $m$ in $O(m)$\\nspace and $O(m (\\\\log \\\\sigma_{RLE_{S}} + \\\\sqrt{\\\\log m / \\\\log\\\\log m}))$ time so\\nthat all $\\\\mathit{SUPSs}$ for any subsequent query interval can be answered in\\n$O(\\\\sqrt{\\\\log m / \\\\log\\\\log m} + \\\\alpha)$ time, where $\\\\alpha$ is the number of\\noutputs, and $\\\\sigma_{RLE_{S}}$ is the number of distinct runs of $RLE_{S}$.\\n',\n",
       " 'Let $\\\\Sigma$ and $\\\\Pi$ be disjoint alphabets of respective size $\\\\sigma$ and\\n$\\\\pi$. Two strings over $\\\\Sigma \\\\cup \\\\Pi$ of equal length are said to\\nparameterized match (p-match) if there is a bijection $f:\\\\Sigma \\\\cup \\\\Pi\\n\\\\rightarrow \\\\Sigma \\\\cup \\\\Pi$ such that (1) $f$ is identity on $\\\\Sigma$ and (2)\\n$f$ maps the characters of one string to those of the other string so that the\\ntwo strings become identical. We consider the p-matching problem on a\\n(reversed) trie $\\\\mathcal{T}$ and a string pattern $P$ such that every path\\nthat p-matches $P$ has to be reported. Let $N$ be the size of the given trie\\n$\\\\mathcal{T}$. In this paper, we propose the parameterized position heap for\\n$\\\\mathcal{T}$ that occupies $O(N)$ space and supports p-matching queries in\\n$O(m \\\\log (\\\\sigma + \\\\pi) + m \\\\pi + \\\\mathit{pocc}))$ time, where $m$ is the\\nlength of a query pattern $P$ and $\\\\mathit{pocc}$ is the number of paths in\\n$\\\\mathcal{T}$ to report. We also present an algorithm which constructs the\\nparameterized position heap for a given trie $\\\\mathcal{T}$ in $O(N (\\\\sigma +\\n\\\\pi))$ time and working space.\\n',\n",
       " 'Difference-in-differences is a widely-used evaluation strategy that draws\\ncausal inference from observational panel data. Its causal identification\\nrelies on the assumption of parallel trend, which is scale dependent and may be\\nquestionable in some applications. A common alternative method is a regression\\nmodel that adjusts for the lagged dependent variable, which rests on the\\nassumption of ignorability conditional on past outcomes. In the context of\\nlinear models, Angrist and Pischke (2009) show that difference-in-differences\\nand the lagged-dependent-variable regression estimates have a bracketing\\nrelationship. Namely, for a true positive effect, if ignorability is correct,\\nthen mistakenly assuming the parallel trend will overestimate the effect; in\\ncontrast, if the parallel trend is correct, then mistakenly assuming\\nignorability will underestimate the effect. We show that the same bracketing\\nrelationship holds in general nonparametric (model-free) settings. We also\\nextend the result to semiparametric estimation based on inverse probability\\nweighting. We provide three examples to illustrate the theoretical result.\\n',\n",
       " 'Distance preserving visualization techniques have emerged as one of the\\nfundamental tools for data analysis. One example are the techniques that\\narrange data instances into two-dimensional grids so that the pairwise\\ndistances among the instances are preserved into the produced layouts.\\nCurrently, the state-of-the-art approaches produce such grids by solving\\nassignment problems or using permutations to optimize cost functions. Although\\nprecise, such strategies are computationally expensive, limited to small\\ndatasets or being dependent on specialized hardware to speed up the process. In\\nthis paper, we present a new technique, called Distance-preserving Grid\\n(DGrid), that employs a binary space partitioning process in combination with\\nmultidimensional projections to create orthogonal regular grid layouts. Our\\nresults show that DGrid is as precise as the existing state-of-the-art\\ntechniques whereas requiring only a fraction of the running time and\\ncomputational resources.\\n']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstr = []\n",
    "for ele in abst:\n",
    "    rep = (re.sub('[;~!@#$%^&*_?()\\\\//{}~'',.><\"|=+_\\n]','',ele))\n",
    "    rep = rep.replace('\\\\','')\n",
    "    rep = rep.split(' ')\n",
    "    abstr.extend(rep)\n",
    "for i in range(len(abstr)):\n",
    "    abstr[i] = abstr[i].lower()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for line in locals()['In']:\n",
    "#print(line)\n",
    "#save cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word = []\n",
    "with open('stop_words.txt','r') as stop:\n",
    "    for line in stop:\n",
    "        stop_word.append(stop.readline().replace('\\n',''))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "most_words = Counter(abstr).most_common(50+len(stop_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw = []\n",
    "for e in most_words:\n",
    "    if not(e[0] in stop_word):\n",
    "        fw.append(e)\n",
    "fw = fw[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('frequent_words.txt', 'w') as p2:\n",
    "    for pair in fw:\n",
    "        p2.write(pair[0]+' '+str(pair[1])+'\\n')\n",
    "p2.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
